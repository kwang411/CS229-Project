{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from time import time\n",
    "import new_sampler as sampler\n",
    "import old_sampler as sampler2\n",
    "import numpy as np\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 2\n",
    "num_classes = 2\n",
    "num_epochs = 3000\n",
    "batch_size = 150\n",
    "learning_rate = 0.1\n",
    "max_sample_count = 1000\n",
    "sub_sample_count = 150\n",
    "active_dpp_batch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor(np.load('data_synthetic/data3.npy'))\n",
    "labels = torch.LongTensor(np.load('data_synthetic/labels3.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN Model\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(DNN, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(4, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.classifier(x)\n",
    "        return nn.functional.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(train_imgs, train_lbls, test_imgs, test_lbls, verbose=True, batch_size=batch_size):\n",
    "    model = DNN(input_size, num_classes)\n",
    "    \n",
    "    # Loss and train_labelsOptimizer\n",
    "    # Softmax is internally computed.\n",
    "    # Set parameters to be updated.\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0) # weigth decay about 1e-3, 1e-4 is ok  \n",
    "\n",
    "    # Training the Model\n",
    "    for epoch in range(num_epochs):\n",
    "        shuffle_ids = torch.randperm(train_lbls.shape[0])\n",
    "        train_imgs = train_imgs[shuffle_ids]\n",
    "        train_lbls = train_lbls[shuffle_ids]\n",
    "\n",
    "        for i in range(train_lbls.shape[0] // batch_size):\n",
    "            images = train_imgs[i*batch_size : (i+1)*batch_size]\n",
    "            labels = train_lbls[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose and (i+1) % (train_lbls.shape[0] // batch_size) == 0:\n",
    "                print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                       % (epoch+1, num_epochs, i+1, len(train_lbls)//batch_size, loss.item()))\n",
    "\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    images = train_imgs[:]\n",
    "    labels = train_lbls[:]\n",
    "\n",
    "    images = Variable(images)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the train images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "    # Test the Model\n",
    "    images = test_imgs[:]\n",
    "    labels = test_lbls[:]\n",
    "\n",
    "    images = Variable(images)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the test images: %d %%' % (100 * correct / total))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def draw(points):\n",
    "    plt.scatter([x for x, y in points], [y for x, y in points])\n",
    "    plt.xlim(-3*np.pi, 3*np.pi)\n",
    "    plt.ylim(-3*np.pi, 3*np.pi)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 87 %\n"
     ]
    }
   ],
   "source": [
    "# Full model (train = test)\n",
    "model = train_and_test(data, labels, data, labels, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 78 %\n",
      "Accuracy of the model on the test images: 73 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb89513978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random subset model\n",
    "sub_ids = torch.randperm(labels.shape[0])\n",
    "train_ids = sub_ids[:sub_sample_count]\n",
    "test_ids = sub_ids[sub_sample_count:]\n",
    "model = train_and_test(data[train_ids], labels[train_ids], data[test_ids], labels[test_ids], verbose=False)\n",
    "draw(data[train_ids].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHYNJREFUeJztnX+MHdV1x7/HaxstP5ytgzGw4NgqFhERwoSVaWS1DQYMmFSGlDbmD0rSVi4VSGmUoBhFiihRFRNKUxAR1Elpm6oEqgqDBRRDZKkkVKSsyw/zy60DRnjNb7IY5E3t9Z7+8d6D5+d5b+7M/XXunfORLO97b96bOzN3zj3ne87cS8wMRVGUQcyK3QBFUeSjhkJRlFLUUCiKUooaCkVRSlFDoShKKWooFEUpRQ2FoiilqKFQFKUUNRSKopQyO3YDBnHsscfy4sWLB24zue8AJianMNNVYTqLCKMjwxg5co7nFqaHq/P10hsf4MDBmcPenzM0C58+/hgnba2K9oXqbNu27R1mXlC2nWhDsXjxYoyPjw/cZsWGrZienDrs/YUjw3h8/UpfTUsWV+dryfoHUVT8TwDGN1xcv4EWpNoX7ntqAjdt2YE9k1M4cWQY115wKi45czTIvonoVZPtRBuKyX0HsGLD1oEncE9Bxxj0ftNxdb5OHBnGRMF3ThwZrtUuF6TYF+57agLX3bsdUwcOAgAmJqdw3b3bAcDKWLg2PqI1ionJKUxMToHx8Qm876mJQ7bp1zFjdljJuDpf115wKobnDB3y3vCcIVx7wam121bGfU9NYMWGrViy/kGs2LA1Sl8oa0NVbtqy4yMj0WHqwEHctGWHVRuvu3d76b1TBdGGYqbnydaiExijw8bEtqO6Ol+XnDmK737xdIyODIMAjI4M47tfPN2by2zS+X33BR83oA8vyIfxER16FNF7AjsdM1aMFxIXbqrL83XJmaPBzvOgzt9pg+++YNKGqvgI4XwYn+QMRdEJDNlhY+Kqo6Z4vkw7v89j83EDXnvBqYcYf8DeC/JhfESHHrOIDnmdc0hhQgixznUM7goJWpSPNvgI4XyEYKI9itGRYSwcGc4+pDDFd6bBlwLvAtOR12eq0cfoD7j3gnyEYCR5KryxsTEuq6NoEr03MtDqqK5ExBUbthYaolEhdQhlRsD3+TFpQ2oQ0TZmHivbTrRHIZGYHcW3WCe9DqFs5PUhNlZtQ66ooaiAiWvu25D47KgSi6iqIN3QpYxoMVMaZflpH3n2kKRekyJB8MwVNRQVKBuxfBS6hCR0EZVrUjd0ktHQowJlrnkOrm/KMXiTiu9Co4aiAmXpMekxfm6KfRGuDV0TzpkJaigqUDZi+cqzu0ByjYRUfJ+zlIyQ1lE4RurFj1UjIfV8mODznIWo+TBB6ygiYer6hr6BYugnqXsxPs9ZiJoPl1hnPYjoVCJ6uuvfXiL6i55tPk9E73dt823b/aZMjDRqjNRh6lkgn+csNeHb2lAw8w5mXsbMywCcBWAfgE0Fm/6ssx0z32C735SJcQPFSB2mdjP04vOcpVbz4bqO4lwAv2Rmo3n4TJH6RGNdYtxAMWokUrsZevF5zlKr+XCtUawF8JM+n32OiJ4BsAfAN5j5eZMfTD3OLSJWGjV0jYTELFBVbcjXObOt+QitcTnLehDRXLSMwGeY+c2ez+YBmGHmD4loNYBbmHlpn99ZB2AdACxatOisk/78H0Q/0VgHKYp3CCRlPXI57y6PwzTr4dJQrAFwNTOvMth2F4AxZn5n0HZjY2P87nl/2Xda+FciTQvvAkk3UFOQ/hi9KS6PI0Z69HL0CTuI6HgAbzIzE9FytLSRd01+1IWbLvGmTLlUOlVSF1c7xDgOJ2ImER0J4HwA93a9dxURXdV+eRmA59oaxa0A1rKhK2Mr+qT+RKdrchOGq5C6uNrBxXF0+sHc4085y2R7J4aCmfcx8yeZ+f2u9+5g5jvaf9/GzJ9h5jOY+beY+T9Nf9tWeU49l++SqkYzN6OSWqahHy4HT1OSqMy0cdNzcTddUKUaUFK2yVXomMvTpbbHUdQPykjCUNhgo3FI1DZsqGI0pZQYuzZYuWhDPgbPQWQ/cU1dNy1HbaNKbCvFE9PQ0T11NJnsDUVdjSPHDlrFaEoR/lwarBCai+0+QrSxqB+UkX3oAdRz06SMqC6pEttKqap0VcUaQnOx3UcoXai7H7xu+B2dj6IPuRTn2CBBo3FVhRjietruI0af0/koLJEyosZEgvDnKlMRwkO03YdkL1YNRR9ySaXlgAuDFeJBPNt9SJ5zNXsx04ZLzhzF4+tX4pUNF+Px9SvVSCRMiGIr231ILghTj0JpBCE8RNt9SPZiVcwMiARx0DdNOMacUDFTGJJKon3RhGNsKo0yFDFHOykl0T4JcYzqscShMYYi9mgnOfXlCt/HGPsaNpnGZD1il2RLKYn2ie9jjH0Nm4xoQzG574CzuvfYI7rk1JcrfB9j7GsoGd/PiIgOPSYmpzDd7gS2bmbsYhbJqS9X+D7G2NdQKiFCMtHp0SNOWMonXPm3h7xXt+49lxmYm4ztNcxVCLV5RiTb9GhdN7MJI3ru2FzDnIXQECFZcobCxs2U8JBTakgbhetew5zT0yFCMmdiJhHtIqLt7UWIDyunpBa3EtFOInqWiD5b2jiiQ17nJv5VJfRktznN8pWzEBpCKHed9TinvQhxUcxzEYCl7X/rANxe9mOjI8NB18qUTIybNqd0ZM7p6RDryoYMPdYA+HF7PY8niGiEiE5g5r6T7IwcOUfEJDES3O8YrnNOo3Du84v4DqtdehQM4BEi2tZeP7SXUQCvdb3e3X7vEIhoHRGNE9H422+/7bB59ZDifse4aXMahWOs5p4TLj2KFcy8h4iOA/AoEb3EzI91fU4F3zksN8vMGwFsBFpPjzpsXy2kiGAxaghyG4UlitkSvFUTnHkUzLyn/f9bADYBWN6zyW4AJ3e9Pgmt1c9FI8X9jlHZqaOwX6R4qyY48SiI6CgAs5j5g/bfqwDc0LPZZgDXENHdAM4G8P4gfUIKUqoBY9WBSByFQxBipJfirZrgKvRYCGATtdKZswHcxcwPdxYpbq9B+hCA1QB2AtgH4CuO9l2ZKp1Akvvd1Js2NC6Ks0z6mBRv1QQnhoKZXwZwRsH7d3T9zQCudrE/G6p2Aq3obB62I71pH5PirZqQXGWmLXU6gY7kzcJ2pDftY5K81TKSNRR1Y8iU3D3JpKLW18F2pDftYyl5q0kaCpsYMiV3Tyo5P2AF2I/0VfpYKG/V1rCLnrimHzalxU2YQMY3OZV2F2GbFpbWx1ykYZP0KGzChyJ375xPL8BNW3bga/c8Ldr9k0Ks8C1kuGMz0ksLKVwY9iQNhW340N0JfLrRucbxMcK31MIdSQK4C8OeZOjh0rXz5UanVHVXlRiude7hjk9cPLOTpKFwWVrsy42O1bFDzFkRo7Rbs1X1cWHYkww9AHeunS83OkbHDumeh3atNVtVHxeaSbKGwhW+il5idOyUnh2oSkrFSRKxNeyNNxS+FGrbjl1HCLX1YiSLr9IyCU2j8YYC8ONGx5gx2saLSSGrICmT0DTUUHgk9IzRNl5MzmGLYo8aCoHUDSFsvJicswqSQ6pUUEMhEJsQoq4XE1J8DXnjphBSpUCSdRS5E6OgKdQ+QxeiuapnCb2mijTUoxBIDIU/1D5DayEuQqpQXonkEEkNhVBiKPwh9hlaC3ERUoUwbibGKKYh0dBDsaaKWx56rRAXIVUI41YWIsV+digLQ9H0+DEmVTtwaP3FxXMpIYxbmTGK/VCcdehBRCcD+DGA4wHMANjIzLf0bPN5APcDeKX91r3M3Dudfy1U1Y5LVbc8lv5i8/shysfLQqTY6WsXGsU0gK8z838T0TEAthHRo8z8Qs92P2PmLzjY3yFooVBc6nTg1CosQxi3MmMU+6E4a0PRXsTn9fbfHxDRi2itKdprKLwQ29I2ndgdOBS+jVuZMYr9UJzTrAcRLQZwJoBfFHz8OSJ6Bq1lBL/BzM/3+Y11ANYBwKJFi0r32ZSOKpXYHTgnBhmj2A/FUWtdHgc/RHQ0gP8A8FfMfG/PZ/MAzDDzh0S0GsAtzLy07DfHxsZ4fHx84Da9GgXQ6qi6RmY4JOf/lcEQ0TZmHivdzoWhIKI5AB4AsIWZ/8Zg+10Axpj5nUHbmRgKQH5H1falTc7nx9RQuMh6EIC/B/BiPyNBRMcDeJOZmYiWo5WWfdd23x0ki2PSszLS2xcbPT8tXNRRrABwBYCVRPR0+99qIrqqs0gxgMsAPNfWKG4FsJZdxTzCiZ3/LkN6+2Kj56eFi6zHzwFQyTa3AbjNdl8pIj0rI719sdHz0yKLykzJhC5Zror09sVGz08LNRSekba8XC/S2ietHF/a+YmFPj06ABdqd+z8dxmS2idROJR0fmLirI7CB2XpUZ9pK63PCM+KDVsLi+dGR4bx+PqVEVqUP8HSo7HwPfpIfoYk17x+U4XDFK5nshqF77SV1E4be14CnzRROEzleiZrKHzfyFI7bc55/SYKh6lcz2QNhe8bWWqnlerpuMBmkhlp2RJTUrmeyWoUvp9alKp25/60bJ1yfInZElNSuZ7JGooQN7LEZ0j0se7DkSw8l5HK9UzWUAAyb2TfSPV0YpKK+15EKtczaUPRVEwMZAopN1ek4r73I4UBL1kxU+lPKik3V0gVnnNCPYoMSTlmr0Mq7ntsirxMU9RQZEjKMXtdUnDfY9IvMzRreN58k++rociQ1GP2kDRFy+nnZQ4dPd/oYFWjyJBUYvbYRVJN0nL6eZM0NHuuyffVUGSIi2X0fCPhJk2lfNoF/bxJPji93+T7GnpkivSYXYLg2iQtp19h18EP3zOyzE48CiK6kIh2ENFOIlpf8PkRRHRP+/NftBcKCk5sV1f5GAk3qdQH/3zQz8ucmdr7nsn3XUzXPwTgBwDOB7AbwJNEtLln7dE/AfArZj6FiNYCuBHAl2z3XYWUnwfIEQmCayrl066w8TJdeBTLAexk5peZeT+AuwGs6dlmDYB/av/9bwDOba8HYkUVD6FJ8WgKSBBcU9BypOBCoxgF8FrX690Azu63DTNPE9H7AD4JYOBKYYOo6iFIcHVNaEq6TkqRlC8tJ7fr6MJQFHkGvRNxmmzT2tBwkeKqYpgEV7eMpoVH0gXXuuR4HV2EHrsBnNz1+iS0Viwv3IaIZgP4BIBCEYWZNzLzGDOPLViwoO9Oq3oIElzdMjQ8yoMcr6MLQ/EkgKVEtISI5gJYC2BzzzabAVzZ/vsyAFttlxSsqlinEI+mEh4pg8nxOrpYUnCaiK4BsAXAEIA7mfl5IroBwDgzb0ZrEeN/JqKdaHkSa233W0exlu7qphAeVSW3WN0E2+so8Zw5Kbhi5ocAPNTz3re7/v41gD9wsa8OUsQwl0hP11XtwDnG6ibYXEep5yzpBYByROJo0mlX1QWRmrygT93rGPqcZb8AUK5IDY/qlFzHiNWlGNq611GqvqEPhSlG1OnAoUukJTxoZovUsnI1FIoRdTpw6JR0DmlJqWl8NRSKEXU6cOiUtFS3vQpS0/iqUShG1M0yhdRcckkvS9SpsjMUUsSsUIQ8XokduBvp6eWUycpQ+MpBSzU+UnPuscixtkYKWdVR+MhB16kfCEWT6xQUM8oGuUbWUfgQsyRM2daPHMS7JhDLI3XpcWaV9fCRg5Z8M7o4Xp0e0C8xaztcpouzMhQ+ctBSC2AA++PNoUBJOjFrO1wOclkZCh85aKkFMID98eZQoCSdmB6py0EuK40CcJ/Ck66k2xyvpLBKambJlpi1HS7TxdkZCh9Irh+wucGkFCilkOate55j1na4HOREp0ePOGEpj33177IZXVxjm7qVkvqVnuZ1cZ6lekvZpEclji5SsE3dSgmrJIVARbg4z6n3XfGGApBTtyANFzeYhE4sJQTqh3RDFoJksh5NuiimSE7dVkFyZgnI5zzbkIyhaNJFMUX6DWaK1EerO+Rynm2wCj2I6CYAvwdgP4BfAvgKM08WbLcLwAcADgKYNhFPumnaRTFFisbgQqyTEAL1Q8p5jolV1oOIVqG1Rsc0Ed0IAMz8zYLtdgEYY+ZKSwhq1kM+UjInSj1Msx5WoQczP8LM0+2XT6C1SpgzTh/9BB5fv1I7nGC0urMZuNQo/hjAv/f5jAE8QkTb2muLKpmgGYFmUKpRENFPARxf8NG3mPn+9jbfAjAN4F/6/MwKZt5DRMcBeJSIXmLmx/rsz2iR4tBILpqJifTUpuKGUkPBzOcN+pyIrgTwBQDn9ltPlJn3tP9/i4g2AVgOoNBQMPNGABuB1sQ1Ze0LQQolxrHQ6ec+JufBxDbrcSGAbwL4XWbe12ebowDMYuYP2n+vAnCDzX5DI3nymthoRqBFKoNJrzGbNTxvvsn3bCszbwNwBFrhBAA8wcxXEdGJAH7EzKsBLASwqf35bAB3MfPDlvsNisbhgwmV2pQ8YqcwmBQZs9nzFnzK5LtWhoKZT+nz/h4Aq9t/vwzgDJv9xEbj8PhIH7FTGEyKjBmIjBIayVRmxkQr8/xTNiWf9DRsCmXeNkYriYfCYqNxuF9MvIUQI7ZNaONa1PURZvXzjE1QQ2GI5BJjl8TQAUzie9/hn21o43Iw8RVmFRkzMM+YfDc7QyFZ8AJkty+WDmDiLfhOw7oQI10NJr6E0SJj9tret181+W5WhkK64CW9fbGUexNvwXf4J0mM9NmWXmNG1+19z+R7WRkK6Skq6e2LdbOYegs+wz9JmS1JbemQVdZD0qhQhPT2xVLuJcxHISmzJaktHbLyKCRa4m7qtC+kphF7xuiYXpWkzJaktnQQPQt31UWKpc+NULV9MY5HstiquMd0PgrRhuKU087ghX/0/UqdVnpHr9I+6dPYK+mTxXT9E5NTmG7fKKYZgtgubBlV2idd01Cag2gxc6bH23Fdsit9Je8UyoKVZiDaUBThajRNYSVvl+q3dKOoyCY5Q+FqNJX+kBHgLm2YglFUZCNao5jVmsPiI1ym6lKJ/11oLtILvRT5iPYoRkeGvRXhNCn+T8UoKnIR7VGMHDnHWxqwSXM92haiuU45x0phS0+dS0a0ofCJxOo3X9gYRdcPssV6MK7OftWwfIzogquqlZlKf+p2etdFX7GKyKruV3qVryuyKLhS3FFXFHWtb8TSS6ruVwXgQ7ESM4noeiKaIKKn2/9W99nuQiLaQUQ7iWi9zT6VsLgWfWOJyFX3qwLwobjIenyfmZe1/z3U+yERDQH4AYCLAJwG4HIiOs3BfpWK1Cm6cv3Ic6xHqKvut0lZMRNChB7LAexsT9sPIrobwBoALwTYd1Aki191RUTXom8sEbnqfmNkxST3Hysxk4iuB/BlAHsBjAP4OjP/qmebywBcyMx/2n59BYCzmfmast9PScyULn7pk6jVCXnjxuo/zsTMQYsUA7gdwHfQWq38OwBuRmtV80N+ouC7fa2T1EWKy5AufmnMXZ2QTyLX6T8hDZn1IsUdiOiHAB4o+Gg3gJO7Xp8EYM+A/TlbpDjkiZR+I0qf/avpVO0/oetRbLMeJ3S9vBTAcwWbPQlgKREtIaK5ANYC2GyzXxNCPwglXfySOA9jSKQ/PVu1/4R+qNE26/E9ItpORM8COAfA1wCAiE4koocAgJmnAVwDYAuAFwH8KzM/b/Ljk/sO1L64oU+k9BtRwgS2sUjh6dmq/aeuB9trMIOsZs7MV/R5/6NFituvHwJwWOq0jDozXHUIHQqkUBIuffYvX0jXj4Dq/afuRM1RVjP3Tb8ZrkwuboyYvKk3onSk60cdqvSfOunbRq1mbnpxpYcCVZAeX0tHun5UhzqhZKNWMze9uFVdOanFLtKXIUyBXKcUqOrBZruaue0MV6YnUvLNGDq+lmowbUhBPwpBtquZj44MY+HIsPeLK1nsChlfSzGYPoyV6kcZr2buc4arbiSLXSFFWQkGU4qxypW6q5knJ2b6QLLYFVKUlWAwU5gdvYmooYDsDEnIQikJBlOCsZJI7MyX6NAjFNLFrlDxtYTsQE7PpLjSWiSEY2oo2qjYJcNgSjBWLnB5c7vQjmyNlhqKHnJMD1YhtsGUYKxc4FIYtg3HBhktU9RQdBHKxWu6MSojtrFygUutxTYccyEQq5jZRQjFPYUnGRV7XArDtmK7C6OlhqKLEIp7Lum/2Cp8FWK01WUmzTbz5cJoiQ49OvNRhHLRQyjuOaT/JKjwpsRqq49Jiet+d5BAfOl1Zr8h2lDYzEdRh7qKexXNwaUxiqV1SKjgNCVmW6VoLS6MlmhDYTMfRR3qnNCqI5ar9F/MUT0lryiltvrE1miJNhRF+L7AVU9o1RHLlUsac6QMXRRl4znlVMAVk+QMhbQLXGfEcuGSxhwpQxZF2XpOuRRwxUZ01sN2PooQpLKWpktCPn9imyVq8qTCLrHyKIjoHgCdO3cEwCQzLyvYbheADwAcBDBtsjIREG4+ChtijVixR8pQQp0Lz0mKqJgytrNwf6nzNxHdDOD9AZufw8zvVPn9UPNR2JDKWpqpohqDDJxoFEREAP4QgOy72hOxRqwmjJSxPSelhSuN4rcBvMnM/9vncwbwCBFta68tqihGqMYgA6tFipn5/vbflwP4yYCfWcHMe4joOACPEtFLzPxYn/0luUix4g8JnlPTH+QjZqt1gEFEswFMADiLmXcbbH89gA+Z+a/Lth0bG+Px8XGr9imKLb0pWqAV/uTg2RDRNpPkgovQ4zwAL/UzEkR0FBEd0/kbwCoUL2asRCSlh7xCk8uDfDa4MBRr0RN2dC9SDGAhgJ8T0TMA/gvAg8z8sIP9Ko7QR98Ho2XgDrIezPzlgvc+WqSYmV8GcIbtfnInZgwcohw85Rhfeoo2xLkVXZnZFGKP6L5HzNjHZ4vkWdpDnVs1FAKIHQP7LgePfXy2SE7Rhjq3yT0UliOxY2DfRU2xj88FElK0RYQ6t0kbipTj3m5ix8C+y8FjH1/OhDq3yRqKlKZjK0NCmbLPEVPC8eVKqHObrKGQMh2bC68m9we8cj++mIQ6t9aVmT4ZVJm5ZP2DKGo5AXhlw8WV91Xnhs+5Yi93cglbbQlZmRkFl0p93RRT6mp+U0k9XRuDZA2Fy9x23Rs+BzW/g4QS7lBtUANfnWQ1CpexWd0bPhc1X4IwHLINORn4UCRrKAB3Sn3dGz4XNV+CMByyDbkY+JAkG3q4pG4YI7lirwoSRti6bagTrkguyZaKeI8ihDptE8ZIqtire64kjLB12lA3XGlyura3j8wanjff5Hui06OnnHYGz/n9GzX9aIBNqlZCmrdOG1Zs2FpoXEZHhqNNyiw57Vp0jl//x6/O/N8bO4cGfA2A8NDjjb2/VnXaEBslX0IIVacNEkKmbqSnXYv6CIiMbIDo0OPAwZnC91WdPhzbm0ZCCFW1DRJCpm4kiMKDsLlvRHsUc4aKm6fq9OHEXDksFtJESWkeTi82fUG0RkGz5+6de+yiow5xj5hnpve+/erM1N73IjatDscCqLQAUhVmDc+bP3vegk9FPldej7GIWcPz5g8dPX+UhmbP5YPT+w9++N5EgOMtPM45CxafTkOz5/a+zwen9x94e9d2z20qpaiPTE++yQen9pY6DKINRU4Q0bjpUoqp0oRjBJpznN2IDj0URZGBGgpFUUpRQxGOjbEbEIAmHCPQnOP8CNUoFEUpRT0KRVFKUUMRCCK6nogmiOjp9r/VsdvkEiK6kIh2ENFOIlofuz2+IKJdRLS9fQ0bszCuhh6BqLI4c2oQ0RCA/wFwPoDdAJ4EcDkzvxC1YR4gol0Axpg5aL1IbNSjUFywHMBOZn6ZmfcDuBvAmshtUhyihiIs1xDRs0R0JxH9RuzGOGQUwGtdr3e338sRBvAIEW0jonWxGxMKNRQOIaKfEtFzBf/WALgdwG8CWAbgdQA3R22sW6jgvVxj2hXM/FkAFwG4moh+J3aDQiD66dHUYObzTLYjoh8CeMBzc0KyG8DJXa9PArAnUlu8wsx72v+/RUSb0Aq7HovbKv+oRxEIIjqh6+WlAJ6L1RYPPAlgKREtIaK5ANYC2By5Tc4hoqOI6JjO3wBWIa/r2Bf1KMLxPSJahpZLvgvAn8VtjjuYeZqIrgGwBcAQgDuZ+fnIzfLBQgCbiAho3Tt3MfPDcZsUBk2PKopSioYeiqKUooZCUZRS1FAoilKKGgpFUUpRQ6EoSilqKBRFKUUNhaIopaihUBSllP8HWn8tJGWmCqYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb894ca588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Passive DPP subset model\n",
    "train_ids = sampler.sample_ids_mc(data.numpy(), np.ones(labels.shape[0]), k=sub_sample_count, alpha=4., gamma=0.)\n",
    "\n",
    "mask=np.full(labels.shape[0], True, dtype=bool)\n",
    "mask[train_ids] = False\n",
    "test_ids = np.arange(labels.shape[0])[mask]\n",
    "\n",
    "model = train_and_test(data[train_ids], labels[train_ids], data[test_ids], labels[test_ids], verbose=False)\n",
    "\n",
    "draw(data[train_ids].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active DPP subset model (new sampler)\n",
    "scores = np.ones(labels.shape[0])\n",
    "train_ids = []\n",
    "\n",
    "batches = [60, 40, 20, 20, 20, 20, 20]\n",
    "\n",
    "for i in range(len(batches)):\n",
    "    new_train_ids = sampler.sample_ids_mc(data.numpy(), scores, k=batches[i], alpha=2., gamma=2., filename='temp.obj')\n",
    "    train_ids = np.append(train_ids, new_train_ids).astype(np.int)\n",
    "    os.remove(\"temp.obj\")\n",
    "    \n",
    "    mask=np.full(labels.shape[0], True, dtype=bool)\n",
    "    mask[train_ids] = False\n",
    "    test_ids = np.arange(labels.shape[0])[mask]\n",
    "\n",
    "    model = train_and_test(data[train_ids], labels[train_ids], data[test_ids], labels[test_ids], verbose=False, batch_size=len(train_ids))\n",
    "    \n",
    "    out = model(data[test_ids])\n",
    "    out = out.detach().numpy()\n",
    "    entropies = np.sum(-out*np.log(out),axis=1)\n",
    "    \n",
    "    scores = np.zeros_like(scores)\n",
    "    scores[test_ids] = entropies\n",
    "    \n",
    "    draw(data[train_ids].detach().numpy())\n",
    "    #import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active DPP subset model (old sampler w/ conditioning)\n",
    "scores = np.ones(labels.shape[0])\n",
    "train_ids = []\n",
    "\n",
    "batches = [200]\n",
    "\n",
    "for i in range(len(batches)):\n",
    "    new_train_ids = sampler2.cond_sample_ids(data.numpy(), scores, cond_ids=train_ids, k=batches[i], gamma=0.)\n",
    "    train_ids = np.append(train_ids, new_train_ids).astype(np.int)\n",
    "    \n",
    "    mask=np.full(labels.shape[0], True, dtype=bool)\n",
    "    mask[train_ids] = False\n",
    "    test_ids = np.arange(labels.shape[0])[mask]\n",
    "\n",
    "    model = train_and_test(data[train_ids], labels[train_ids], data[test_ids], labels[test_ids], verbose=False, batch_size=len(train_ids))\n",
    "    \n",
    "    out = model(data)\n",
    "    out = out.detach().numpy()\n",
    "    scores = np.sum(-out*np.log(out),axis=1)\n",
    "    \n",
    "    draw(data[train_ids].detach().numpy())\n",
    "    #import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 100 %\n",
      "Accuracy of the model on the test images: 69 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 58 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 60 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 62 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 59 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 59 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 58 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 57 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 100 %\n",
      "Accuracy of the model on the test images: 67 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 64 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 100 %\n",
      "Accuracy of the model on the test images: 70 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 59 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 59 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 100 %\n",
      "Accuracy of the model on the test images: 66 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb8943a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 76 %\n",
      "Accuracy of the model on the test images: 69 %\n",
      "Accuracy of the model on the train images: 66 %\n",
      "Accuracy of the model on the test images: 62 %\n",
      "Accuracy of the model on the train images: 90 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 66 %\n",
      "Accuracy of the model on the test images: 62 %\n",
      "Accuracy of the model on the train images: 90 %\n",
      "Accuracy of the model on the test images: 76 %\n",
      "Accuracy of the model on the train images: 66 %\n",
      "Accuracy of the model on the test images: 62 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 70 %\n",
      "Accuracy of the model on the test images: 63 %\n",
      "Accuracy of the model on the train images: 66 %\n",
      "Accuracy of the model on the test images: 61 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 73 %\n",
      "Accuracy of the model on the train images: 73 %\n",
      "Accuracy of the model on the test images: 58 %\n",
      "Accuracy of the model on the train images: 66 %\n",
      "Accuracy of the model on the test images: 62 %\n",
      "Accuracy of the model on the train images: 70 %\n",
      "Accuracy of the model on the test images: 59 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 71 %\n",
      "Accuracy of the model on the train images: 76 %\n",
      "Accuracy of the model on the test images: 68 %\n",
      "Accuracy of the model on the train images: 70 %\n",
      "Accuracy of the model on the test images: 63 %\n",
      "Accuracy of the model on the train images: 66 %\n",
      "Accuracy of the model on the test images: 62 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 70 %\n",
      "Accuracy of the model on the test images: 53 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb893aafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 78 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 79 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 80 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 80 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 79 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 79 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 91 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 73 %\n",
      "Accuracy of the model on the test images: 71 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 77 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb893aaeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 90 %\n",
      "Accuracy of the model on the test images: 78 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 71 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 65 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 76 %\n",
      "Accuracy of the model on the train images: 78 %\n",
      "Accuracy of the model on the test images: 76 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 74 %\n",
      "Accuracy of the model on the train images: 91 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 78 %\n",
      "Accuracy of the model on the test images: 55 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 73 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 93 %\n",
      "Accuracy of the model on the test images: 70 %\n",
      "Accuracy of the model on the train images: 91 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 73 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 81 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb8931a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 90 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 80 %\n",
      "Accuracy of the model on the train images: 72 %\n",
      "Accuracy of the model on the test images: 64 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 74 %\n",
      "Accuracy of the model on the train images: 64 %\n",
      "Accuracy of the model on the test images: 53 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 80 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 80 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 82 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb89436c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 90 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 74 %\n",
      "Accuracy of the model on the test images: 60 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 88 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 91 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 79 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 82 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb893aab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 89 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 85 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb891d04a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 87 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 71 %\n",
      "Accuracy of the model on the test images: 57 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 81 %\n",
      "Accuracy of the model on the test images: 80 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 82 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 86 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 74 %\n",
      "Accuracy of the model on the test images: 76 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb893aacc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 83 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 79 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 77 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 81 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 77 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 76 %\n",
      "Accuracy of the model on the test images: 84 %\n",
      "Accuracy of the model on the train images: 78 %\n",
      "Accuracy of the model on the test images: 82 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 87 %\n",
      "Accuracy of the model on the train images: 79 %\n",
      "Accuracy of the model on the test images: 81 %\n",
      "Accuracy of the model on the train images: 82 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 79 %\n",
      "Accuracy of the model on the test images: 83 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 83 %\n",
      "Accuracy of the model on the test images: 87 %\n",
      "Accuracy of the model on the train images: 83 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 79 %\n",
      "Accuracy of the model on the test images: 85 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb894a0ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the train images: 76 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 78 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 85 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 77 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 78 %\n",
      "Accuracy of the model on the test images: 74 %\n",
      "Accuracy of the model on the train images: 83 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 83 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 82 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 89 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 77 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 83 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 77 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 86 %\n",
      "Accuracy of the model on the train images: 80 %\n",
      "Accuracy of the model on the test images: 85 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 87 %\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 88 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb89490e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Active DPP subset model (new sampler w/ conditioning)\n",
    "scores = np.ones(labels.shape[0])\n",
    "train_ids = []\n",
    "\n",
    "batches = [15]*10\n",
    "\n",
    "for i in range(len(batches)):\n",
    "    k = int(np.ceil(2.0*batches[i]/3))\n",
    "    #k = batches[i]\n",
    "    new_train_ids = sampler.cond_sample_ids_mc(data.numpy(), scores, cond_ids=train_ids, k=k, alpha=4., gamma=5.)\n",
    "    train_ids = np.append(train_ids, new_train_ids).astype(np.int)\n",
    "    new_train_ids = sampler.cond_sample_ids_mc(data.numpy(), scores, cond_ids=train_ids, k=batches[i]-k, alpha=4., gamma=0.)\n",
    "    train_ids = np.append(train_ids, new_train_ids).astype(np.int)\n",
    "    \n",
    "    mask=np.full(labels.shape[0], True, dtype=bool)\n",
    "    mask[train_ids] = False\n",
    "    test_ids = np.arange(labels.shape[0])[mask]\n",
    "\n",
    "    \n",
    "    out = np.zeros((20,data.shape[0],num_classes))\n",
    "    models = []\n",
    "    for j in range(20):\n",
    "        models.append(train_and_test(data[train_ids], labels[train_ids], data[test_ids], labels[test_ids], verbose=False, batch_size=len(train_ids)))\n",
    "        out[j,:,:] = models[j](data).detach().numpy()\n",
    "    \n",
    "    out = np.mean(out, axis=0)\n",
    "    scores = np.sum(-out*np.log(out),axis=1)\n",
    "    scores[scores!=scores] = 0 # because 0*log(0)=0\n",
    "    scores = scores + 1e-8 # just to make sure condition is not zero-probability\n",
    "    \n",
    "    draw(data[train_ids].detach().numpy())\n",
    "    #import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/3000], Step: [1/1], Loss: 0.6923\n",
      "Epoch: [2/3000], Step: [1/1], Loss: 0.6954\n",
      "Epoch: [3/3000], Step: [1/1], Loss: 0.6873\n",
      "Epoch: [4/3000], Step: [1/1], Loss: 0.6841\n",
      "Epoch: [5/3000], Step: [1/1], Loss: 0.6848\n",
      "Epoch: [6/3000], Step: [1/1], Loss: 0.6832\n",
      "Epoch: [7/3000], Step: [1/1], Loss: 0.6804\n",
      "Epoch: [8/3000], Step: [1/1], Loss: 0.6788\n",
      "Epoch: [9/3000], Step: [1/1], Loss: 0.6783\n",
      "Epoch: [10/3000], Step: [1/1], Loss: 0.6774\n",
      "Epoch: [11/3000], Step: [1/1], Loss: 0.6756\n",
      "Epoch: [12/3000], Step: [1/1], Loss: 0.6734\n",
      "Epoch: [13/3000], Step: [1/1], Loss: 0.6722\n",
      "Epoch: [14/3000], Step: [1/1], Loss: 0.6706\n",
      "Epoch: [15/3000], Step: [1/1], Loss: 0.6689\n",
      "Epoch: [16/3000], Step: [1/1], Loss: 0.6670\n",
      "Epoch: [17/3000], Step: [1/1], Loss: 0.6646\n",
      "Epoch: [18/3000], Step: [1/1], Loss: 0.6621\n",
      "Epoch: [19/3000], Step: [1/1], Loss: 0.6599\n",
      "Epoch: [20/3000], Step: [1/1], Loss: 0.6577\n",
      "Epoch: [21/3000], Step: [1/1], Loss: 0.6555\n",
      "Epoch: [22/3000], Step: [1/1], Loss: 0.6526\n",
      "Epoch: [23/3000], Step: [1/1], Loss: 0.6491\n",
      "Epoch: [24/3000], Step: [1/1], Loss: 0.6457\n",
      "Epoch: [25/3000], Step: [1/1], Loss: 0.6421\n",
      "Epoch: [26/3000], Step: [1/1], Loss: 0.6384\n",
      "Epoch: [27/3000], Step: [1/1], Loss: 0.6358\n",
      "Epoch: [28/3000], Step: [1/1], Loss: 0.6325\n",
      "Epoch: [29/3000], Step: [1/1], Loss: 0.6281\n",
      "Epoch: [30/3000], Step: [1/1], Loss: 0.6239\n",
      "Epoch: [31/3000], Step: [1/1], Loss: 0.6206\n",
      "Epoch: [32/3000], Step: [1/1], Loss: 0.6172\n",
      "Epoch: [33/3000], Step: [1/1], Loss: 0.6132\n",
      "Epoch: [34/3000], Step: [1/1], Loss: 0.6096\n",
      "Epoch: [35/3000], Step: [1/1], Loss: 0.6062\n",
      "Epoch: [36/3000], Step: [1/1], Loss: 0.6025\n",
      "Epoch: [37/3000], Step: [1/1], Loss: 0.5989\n",
      "Epoch: [38/3000], Step: [1/1], Loss: 0.5956\n",
      "Epoch: [39/3000], Step: [1/1], Loss: 0.5919\n",
      "Epoch: [40/3000], Step: [1/1], Loss: 0.5875\n",
      "Epoch: [41/3000], Step: [1/1], Loss: 0.5828\n",
      "Epoch: [42/3000], Step: [1/1], Loss: 0.5779\n",
      "Epoch: [43/3000], Step: [1/1], Loss: 0.5725\n",
      "Epoch: [44/3000], Step: [1/1], Loss: 0.5681\n",
      "Epoch: [45/3000], Step: [1/1], Loss: 0.5663\n",
      "Epoch: [46/3000], Step: [1/1], Loss: 0.5611\n",
      "Epoch: [47/3000], Step: [1/1], Loss: 0.5574\n",
      "Epoch: [48/3000], Step: [1/1], Loss: 0.5566\n",
      "Epoch: [49/3000], Step: [1/1], Loss: 0.5535\n",
      "Epoch: [50/3000], Step: [1/1], Loss: 0.5498\n",
      "Epoch: [51/3000], Step: [1/1], Loss: 0.5481\n",
      "Epoch: [52/3000], Step: [1/1], Loss: 0.5465\n",
      "Epoch: [53/3000], Step: [1/1], Loss: 0.5435\n",
      "Epoch: [54/3000], Step: [1/1], Loss: 0.5420\n",
      "Epoch: [55/3000], Step: [1/1], Loss: 0.5416\n",
      "Epoch: [56/3000], Step: [1/1], Loss: 0.5401\n",
      "Epoch: [57/3000], Step: [1/1], Loss: 0.5387\n",
      "Epoch: [58/3000], Step: [1/1], Loss: 0.5382\n",
      "Epoch: [59/3000], Step: [1/1], Loss: 0.5375\n",
      "Epoch: [60/3000], Step: [1/1], Loss: 0.5364\n",
      "Epoch: [61/3000], Step: [1/1], Loss: 0.5350\n",
      "Epoch: [62/3000], Step: [1/1], Loss: 0.5343\n",
      "Epoch: [63/3000], Step: [1/1], Loss: 0.5338\n",
      "Epoch: [64/3000], Step: [1/1], Loss: 0.5329\n",
      "Epoch: [65/3000], Step: [1/1], Loss: 0.5320\n",
      "Epoch: [66/3000], Step: [1/1], Loss: 0.5314\n",
      "Epoch: [67/3000], Step: [1/1], Loss: 0.5309\n",
      "Epoch: [68/3000], Step: [1/1], Loss: 0.5301\n",
      "Epoch: [69/3000], Step: [1/1], Loss: 0.5294\n",
      "Epoch: [70/3000], Step: [1/1], Loss: 0.5289\n",
      "Epoch: [71/3000], Step: [1/1], Loss: 0.5285\n",
      "Epoch: [72/3000], Step: [1/1], Loss: 0.5280\n",
      "Epoch: [73/3000], Step: [1/1], Loss: 0.5274\n",
      "Epoch: [74/3000], Step: [1/1], Loss: 0.5269\n",
      "Epoch: [75/3000], Step: [1/1], Loss: 0.5265\n",
      "Epoch: [76/3000], Step: [1/1], Loss: 0.5259\n",
      "Epoch: [77/3000], Step: [1/1], Loss: 0.5254\n",
      "Epoch: [78/3000], Step: [1/1], Loss: 0.5249\n",
      "Epoch: [79/3000], Step: [1/1], Loss: 0.5246\n",
      "Epoch: [80/3000], Step: [1/1], Loss: 0.5242\n",
      "Epoch: [81/3000], Step: [1/1], Loss: 0.5238\n",
      "Epoch: [82/3000], Step: [1/1], Loss: 0.5235\n",
      "Epoch: [83/3000], Step: [1/1], Loss: 0.5232\n",
      "Epoch: [84/3000], Step: [1/1], Loss: 0.5228\n",
      "Epoch: [85/3000], Step: [1/1], Loss: 0.5223\n",
      "Epoch: [86/3000], Step: [1/1], Loss: 0.5219\n",
      "Epoch: [87/3000], Step: [1/1], Loss: 0.5215\n",
      "Epoch: [88/3000], Step: [1/1], Loss: 0.5212\n",
      "Epoch: [89/3000], Step: [1/1], Loss: 0.5208\n",
      "Epoch: [90/3000], Step: [1/1], Loss: 0.5203\n",
      "Epoch: [91/3000], Step: [1/1], Loss: 0.5199\n",
      "Epoch: [92/3000], Step: [1/1], Loss: 0.5195\n",
      "Epoch: [93/3000], Step: [1/1], Loss: 0.5191\n",
      "Epoch: [94/3000], Step: [1/1], Loss: 0.5188\n",
      "Epoch: [95/3000], Step: [1/1], Loss: 0.5185\n",
      "Epoch: [96/3000], Step: [1/1], Loss: 0.5182\n",
      "Epoch: [97/3000], Step: [1/1], Loss: 0.5179\n",
      "Epoch: [98/3000], Step: [1/1], Loss: 0.5177\n",
      "Epoch: [99/3000], Step: [1/1], Loss: 0.5174\n",
      "Epoch: [100/3000], Step: [1/1], Loss: 0.5172\n",
      "Epoch: [101/3000], Step: [1/1], Loss: 0.5169\n",
      "Epoch: [102/3000], Step: [1/1], Loss: 0.5166\n",
      "Epoch: [103/3000], Step: [1/1], Loss: 0.5163\n",
      "Epoch: [104/3000], Step: [1/1], Loss: 0.5160\n",
      "Epoch: [105/3000], Step: [1/1], Loss: 0.5156\n",
      "Epoch: [106/3000], Step: [1/1], Loss: 0.5150\n",
      "Epoch: [107/3000], Step: [1/1], Loss: 0.5133\n",
      "Epoch: [108/3000], Step: [1/1], Loss: 0.5109\n",
      "Epoch: [109/3000], Step: [1/1], Loss: 0.5085\n",
      "Epoch: [110/3000], Step: [1/1], Loss: 0.5080\n",
      "Epoch: [111/3000], Step: [1/1], Loss: 0.5079\n",
      "Epoch: [112/3000], Step: [1/1], Loss: 0.5069\n",
      "Epoch: [113/3000], Step: [1/1], Loss: 0.5052\n",
      "Epoch: [114/3000], Step: [1/1], Loss: 0.5041\n",
      "Epoch: [115/3000], Step: [1/1], Loss: 0.5040\n",
      "Epoch: [116/3000], Step: [1/1], Loss: 0.5041\n",
      "Epoch: [117/3000], Step: [1/1], Loss: 0.5039\n",
      "Epoch: [118/3000], Step: [1/1], Loss: 0.5032\n",
      "Epoch: [119/3000], Step: [1/1], Loss: 0.5027\n",
      "Epoch: [120/3000], Step: [1/1], Loss: 0.5024\n",
      "Epoch: [121/3000], Step: [1/1], Loss: 0.5024\n",
      "Epoch: [122/3000], Step: [1/1], Loss: 0.5023\n",
      "Epoch: [123/3000], Step: [1/1], Loss: 0.5020\n",
      "Epoch: [124/3000], Step: [1/1], Loss: 0.5014\n",
      "Epoch: [125/3000], Step: [1/1], Loss: 0.5009\n",
      "Epoch: [126/3000], Step: [1/1], Loss: 0.5007\n",
      "Epoch: [127/3000], Step: [1/1], Loss: 0.5004\n",
      "Epoch: [128/3000], Step: [1/1], Loss: 0.5001\n",
      "Epoch: [129/3000], Step: [1/1], Loss: 0.4997\n",
      "Epoch: [130/3000], Step: [1/1], Loss: 0.4992\n",
      "Epoch: [131/3000], Step: [1/1], Loss: 0.4988\n",
      "Epoch: [132/3000], Step: [1/1], Loss: 0.4986\n",
      "Epoch: [133/3000], Step: [1/1], Loss: 0.4983\n",
      "Epoch: [134/3000], Step: [1/1], Loss: 0.4980\n",
      "Epoch: [135/3000], Step: [1/1], Loss: 0.4977\n",
      "Epoch: [136/3000], Step: [1/1], Loss: 0.4974\n",
      "Epoch: [137/3000], Step: [1/1], Loss: 0.4971\n",
      "Epoch: [138/3000], Step: [1/1], Loss: 0.4969\n",
      "Epoch: [139/3000], Step: [1/1], Loss: 0.4966\n",
      "Epoch: [140/3000], Step: [1/1], Loss: 0.4963\n",
      "Epoch: [141/3000], Step: [1/1], Loss: 0.4961\n",
      "Epoch: [142/3000], Step: [1/1], Loss: 0.4959\n",
      "Epoch: [143/3000], Step: [1/1], Loss: 0.4957\n",
      "Epoch: [144/3000], Step: [1/1], Loss: 0.4954\n",
      "Epoch: [145/3000], Step: [1/1], Loss: 0.4952\n",
      "Epoch: [146/3000], Step: [1/1], Loss: 0.4950\n",
      "Epoch: [147/3000], Step: [1/1], Loss: 0.4948\n",
      "Epoch: [148/3000], Step: [1/1], Loss: 0.4946\n",
      "Epoch: [149/3000], Step: [1/1], Loss: 0.4944\n",
      "Epoch: [150/3000], Step: [1/1], Loss: 0.4943\n",
      "Epoch: [151/3000], Step: [1/1], Loss: 0.4941\n",
      "Epoch: [152/3000], Step: [1/1], Loss: 0.4940\n",
      "Epoch: [153/3000], Step: [1/1], Loss: 0.4938\n",
      "Epoch: [154/3000], Step: [1/1], Loss: 0.4937\n",
      "Epoch: [155/3000], Step: [1/1], Loss: 0.4935\n",
      "Epoch: [156/3000], Step: [1/1], Loss: 0.4933\n",
      "Epoch: [157/3000], Step: [1/1], Loss: 0.4931\n",
      "Epoch: [158/3000], Step: [1/1], Loss: 0.4929\n",
      "Epoch: [159/3000], Step: [1/1], Loss: 0.4926\n",
      "Epoch: [160/3000], Step: [1/1], Loss: 0.4924\n",
      "Epoch: [161/3000], Step: [1/1], Loss: 0.4923\n",
      "Epoch: [162/3000], Step: [1/1], Loss: 0.4921\n",
      "Epoch: [163/3000], Step: [1/1], Loss: 0.4920\n",
      "Epoch: [164/3000], Step: [1/1], Loss: 0.4919\n",
      "Epoch: [165/3000], Step: [1/1], Loss: 0.4917\n",
      "Epoch: [166/3000], Step: [1/1], Loss: 0.4916\n",
      "Epoch: [167/3000], Step: [1/1], Loss: 0.4914\n",
      "Epoch: [168/3000], Step: [1/1], Loss: 0.4912\n",
      "Epoch: [169/3000], Step: [1/1], Loss: 0.4911\n",
      "Epoch: [170/3000], Step: [1/1], Loss: 0.4909\n",
      "Epoch: [171/3000], Step: [1/1], Loss: 0.4907\n",
      "Epoch: [172/3000], Step: [1/1], Loss: 0.4906\n",
      "Epoch: [173/3000], Step: [1/1], Loss: 0.4904\n",
      "Epoch: [174/3000], Step: [1/1], Loss: 0.4903\n",
      "Epoch: [175/3000], Step: [1/1], Loss: 0.4902\n",
      "Epoch: [176/3000], Step: [1/1], Loss: 0.4900\n",
      "Epoch: [177/3000], Step: [1/1], Loss: 0.4899\n",
      "Epoch: [178/3000], Step: [1/1], Loss: 0.4898\n",
      "Epoch: [179/3000], Step: [1/1], Loss: 0.4898\n",
      "Epoch: [180/3000], Step: [1/1], Loss: 0.4897\n",
      "Epoch: [181/3000], Step: [1/1], Loss: 0.4897\n",
      "Epoch: [182/3000], Step: [1/1], Loss: 0.4896\n",
      "Epoch: [183/3000], Step: [1/1], Loss: 0.4894\n",
      "Epoch: [184/3000], Step: [1/1], Loss: 0.4892\n",
      "Epoch: [185/3000], Step: [1/1], Loss: 0.4889\n",
      "Epoch: [186/3000], Step: [1/1], Loss: 0.4887\n",
      "Epoch: [187/3000], Step: [1/1], Loss: 0.4886\n",
      "Epoch: [188/3000], Step: [1/1], Loss: 0.4885\n",
      "Epoch: [189/3000], Step: [1/1], Loss: 0.4885\n",
      "Epoch: [190/3000], Step: [1/1], Loss: 0.4884\n",
      "Epoch: [191/3000], Step: [1/1], Loss: 0.4883\n",
      "Epoch: [192/3000], Step: [1/1], Loss: 0.4882\n",
      "Epoch: [193/3000], Step: [1/1], Loss: 0.4880\n",
      "Epoch: [194/3000], Step: [1/1], Loss: 0.4878\n",
      "Epoch: [195/3000], Step: [1/1], Loss: 0.4877\n",
      "Epoch: [196/3000], Step: [1/1], Loss: 0.4875\n",
      "Epoch: [197/3000], Step: [1/1], Loss: 0.4875\n",
      "Epoch: [198/3000], Step: [1/1], Loss: 0.4874\n",
      "Epoch: [199/3000], Step: [1/1], Loss: 0.4873\n",
      "Epoch: [200/3000], Step: [1/1], Loss: 0.4873\n",
      "Epoch: [201/3000], Step: [1/1], Loss: 0.4872\n",
      "Epoch: [202/3000], Step: [1/1], Loss: 0.4871\n",
      "Epoch: [203/3000], Step: [1/1], Loss: 0.4870\n",
      "Epoch: [204/3000], Step: [1/1], Loss: 0.4869\n",
      "Epoch: [205/3000], Step: [1/1], Loss: 0.4867\n",
      "Epoch: [206/3000], Step: [1/1], Loss: 0.4866\n",
      "Epoch: [207/3000], Step: [1/1], Loss: 0.4864\n",
      "Epoch: [208/3000], Step: [1/1], Loss: 0.4863\n",
      "Epoch: [209/3000], Step: [1/1], Loss: 0.4862\n",
      "Epoch: [210/3000], Step: [1/1], Loss: 0.4861\n",
      "Epoch: [211/3000], Step: [1/1], Loss: 0.4860\n",
      "Epoch: [212/3000], Step: [1/1], Loss: 0.4859\n",
      "Epoch: [213/3000], Step: [1/1], Loss: 0.4858\n",
      "Epoch: [214/3000], Step: [1/1], Loss: 0.4857\n",
      "Epoch: [215/3000], Step: [1/1], Loss: 0.4856\n",
      "Epoch: [216/3000], Step: [1/1], Loss: 0.4856\n",
      "Epoch: [217/3000], Step: [1/1], Loss: 0.4855\n",
      "Epoch: [218/3000], Step: [1/1], Loss: 0.4856\n",
      "Epoch: [219/3000], Step: [1/1], Loss: 0.4856\n",
      "Epoch: [220/3000], Step: [1/1], Loss: 0.4858\n",
      "Epoch: [221/3000], Step: [1/1], Loss: 0.4859\n",
      "Epoch: [222/3000], Step: [1/1], Loss: 0.4857\n",
      "Epoch: [223/3000], Step: [1/1], Loss: 0.4853\n",
      "Epoch: [224/3000], Step: [1/1], Loss: 0.4849\n",
      "Epoch: [225/3000], Step: [1/1], Loss: 0.4847\n",
      "Epoch: [226/3000], Step: [1/1], Loss: 0.4847\n",
      "Epoch: [227/3000], Step: [1/1], Loss: 0.4848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [228/3000], Step: [1/1], Loss: 0.4849\n",
      "Epoch: [229/3000], Step: [1/1], Loss: 0.4847\n",
      "Epoch: [230/3000], Step: [1/1], Loss: 0.4844\n",
      "Epoch: [231/3000], Step: [1/1], Loss: 0.4842\n",
      "Epoch: [232/3000], Step: [1/1], Loss: 0.4841\n",
      "Epoch: [233/3000], Step: [1/1], Loss: 0.4841\n",
      "Epoch: [234/3000], Step: [1/1], Loss: 0.4842\n",
      "Epoch: [235/3000], Step: [1/1], Loss: 0.4841\n",
      "Epoch: [236/3000], Step: [1/1], Loss: 0.4840\n",
      "Epoch: [237/3000], Step: [1/1], Loss: 0.4838\n",
      "Epoch: [238/3000], Step: [1/1], Loss: 0.4836\n",
      "Epoch: [239/3000], Step: [1/1], Loss: 0.4836\n",
      "Epoch: [240/3000], Step: [1/1], Loss: 0.4835\n",
      "Epoch: [241/3000], Step: [1/1], Loss: 0.4835\n",
      "Epoch: [242/3000], Step: [1/1], Loss: 0.4835\n",
      "Epoch: [243/3000], Step: [1/1], Loss: 0.4834\n",
      "Epoch: [244/3000], Step: [1/1], Loss: 0.4832\n",
      "Epoch: [245/3000], Step: [1/1], Loss: 0.4831\n",
      "Epoch: [246/3000], Step: [1/1], Loss: 0.4830\n",
      "Epoch: [247/3000], Step: [1/1], Loss: 0.4829\n",
      "Epoch: [248/3000], Step: [1/1], Loss: 0.4829\n",
      "Epoch: [249/3000], Step: [1/1], Loss: 0.4828\n",
      "Epoch: [250/3000], Step: [1/1], Loss: 0.4828\n",
      "Epoch: [251/3000], Step: [1/1], Loss: 0.4827\n",
      "Epoch: [252/3000], Step: [1/1], Loss: 0.4827\n",
      "Epoch: [253/3000], Step: [1/1], Loss: 0.4826\n",
      "Epoch: [254/3000], Step: [1/1], Loss: 0.4825\n",
      "Epoch: [255/3000], Step: [1/1], Loss: 0.4825\n",
      "Epoch: [256/3000], Step: [1/1], Loss: 0.4824\n",
      "Epoch: [257/3000], Step: [1/1], Loss: 0.4823\n",
      "Epoch: [258/3000], Step: [1/1], Loss: 0.4822\n",
      "Epoch: [259/3000], Step: [1/1], Loss: 0.4821\n",
      "Epoch: [260/3000], Step: [1/1], Loss: 0.4821\n",
      "Epoch: [261/3000], Step: [1/1], Loss: 0.4820\n",
      "Epoch: [262/3000], Step: [1/1], Loss: 0.4820\n",
      "Epoch: [263/3000], Step: [1/1], Loss: 0.4819\n",
      "Epoch: [264/3000], Step: [1/1], Loss: 0.4819\n",
      "Epoch: [265/3000], Step: [1/1], Loss: 0.4818\n",
      "Epoch: [266/3000], Step: [1/1], Loss: 0.4818\n",
      "Epoch: [267/3000], Step: [1/1], Loss: 0.4818\n",
      "Epoch: [268/3000], Step: [1/1], Loss: 0.4819\n",
      "Epoch: [269/3000], Step: [1/1], Loss: 0.4820\n",
      "Epoch: [270/3000], Step: [1/1], Loss: 0.4819\n",
      "Epoch: [271/3000], Step: [1/1], Loss: 0.4818\n",
      "Epoch: [272/3000], Step: [1/1], Loss: 0.4816\n",
      "Epoch: [273/3000], Step: [1/1], Loss: 0.4813\n",
      "Epoch: [274/3000], Step: [1/1], Loss: 0.4812\n",
      "Epoch: [275/3000], Step: [1/1], Loss: 0.4811\n",
      "Epoch: [276/3000], Step: [1/1], Loss: 0.4810\n",
      "Epoch: [277/3000], Step: [1/1], Loss: 0.4810\n",
      "Epoch: [278/3000], Step: [1/1], Loss: 0.4810\n",
      "Epoch: [279/3000], Step: [1/1], Loss: 0.4810\n",
      "Epoch: [280/3000], Step: [1/1], Loss: 0.4810\n",
      "Epoch: [281/3000], Step: [1/1], Loss: 0.4810\n",
      "Epoch: [282/3000], Step: [1/1], Loss: 0.4809\n",
      "Epoch: [283/3000], Step: [1/1], Loss: 0.4808\n",
      "Epoch: [284/3000], Step: [1/1], Loss: 0.4806\n",
      "Epoch: [285/3000], Step: [1/1], Loss: 0.4805\n",
      "Epoch: [286/3000], Step: [1/1], Loss: 0.4804\n",
      "Epoch: [287/3000], Step: [1/1], Loss: 0.4804\n",
      "Epoch: [288/3000], Step: [1/1], Loss: 0.4803\n",
      "Epoch: [289/3000], Step: [1/1], Loss: 0.4803\n",
      "Epoch: [290/3000], Step: [1/1], Loss: 0.4803\n",
      "Epoch: [291/3000], Step: [1/1], Loss: 0.4802\n",
      "Epoch: [292/3000], Step: [1/1], Loss: 0.4802\n",
      "Epoch: [293/3000], Step: [1/1], Loss: 0.4802\n",
      "Epoch: [294/3000], Step: [1/1], Loss: 0.4802\n",
      "Epoch: [295/3000], Step: [1/1], Loss: 0.4802\n",
      "Epoch: [296/3000], Step: [1/1], Loss: 0.4801\n",
      "Epoch: [297/3000], Step: [1/1], Loss: 0.4801\n",
      "Epoch: [298/3000], Step: [1/1], Loss: 0.4800\n",
      "Epoch: [299/3000], Step: [1/1], Loss: 0.4799\n",
      "Epoch: [300/3000], Step: [1/1], Loss: 0.4798\n",
      "Epoch: [301/3000], Step: [1/1], Loss: 0.4797\n",
      "Epoch: [302/3000], Step: [1/1], Loss: 0.4796\n",
      "Epoch: [303/3000], Step: [1/1], Loss: 0.4795\n",
      "Epoch: [304/3000], Step: [1/1], Loss: 0.4794\n",
      "Epoch: [305/3000], Step: [1/1], Loss: 0.4794\n",
      "Epoch: [306/3000], Step: [1/1], Loss: 0.4793\n",
      "Epoch: [307/3000], Step: [1/1], Loss: 0.4793\n",
      "Epoch: [308/3000], Step: [1/1], Loss: 0.4792\n",
      "Epoch: [309/3000], Step: [1/1], Loss: 0.4792\n",
      "Epoch: [310/3000], Step: [1/1], Loss: 0.4792\n",
      "Epoch: [311/3000], Step: [1/1], Loss: 0.4792\n",
      "Epoch: [312/3000], Step: [1/1], Loss: 0.4793\n",
      "Epoch: [313/3000], Step: [1/1], Loss: 0.4793\n",
      "Epoch: [314/3000], Step: [1/1], Loss: 0.4795\n",
      "Epoch: [315/3000], Step: [1/1], Loss: 0.4795\n",
      "Epoch: [316/3000], Step: [1/1], Loss: 0.4796\n",
      "Epoch: [317/3000], Step: [1/1], Loss: 0.4794\n",
      "Epoch: [318/3000], Step: [1/1], Loss: 0.4791\n",
      "Epoch: [319/3000], Step: [1/1], Loss: 0.4788\n",
      "Epoch: [320/3000], Step: [1/1], Loss: 0.4787\n",
      "Epoch: [321/3000], Step: [1/1], Loss: 0.4786\n",
      "Epoch: [322/3000], Step: [1/1], Loss: 0.4786\n",
      "Epoch: [323/3000], Step: [1/1], Loss: 0.4787\n",
      "Epoch: [324/3000], Step: [1/1], Loss: 0.4787\n",
      "Epoch: [325/3000], Step: [1/1], Loss: 0.4788\n",
      "Epoch: [326/3000], Step: [1/1], Loss: 0.4787\n",
      "Epoch: [327/3000], Step: [1/1], Loss: 0.4787\n",
      "Epoch: [328/3000], Step: [1/1], Loss: 0.4785\n",
      "Epoch: [329/3000], Step: [1/1], Loss: 0.4783\n",
      "Epoch: [330/3000], Step: [1/1], Loss: 0.4782\n",
      "Epoch: [331/3000], Step: [1/1], Loss: 0.4781\n",
      "Epoch: [332/3000], Step: [1/1], Loss: 0.4781\n",
      "Epoch: [333/3000], Step: [1/1], Loss: 0.4782\n",
      "Epoch: [334/3000], Step: [1/1], Loss: 0.4782\n",
      "Epoch: [335/3000], Step: [1/1], Loss: 0.4782\n",
      "Epoch: [336/3000], Step: [1/1], Loss: 0.4782\n",
      "Epoch: [337/3000], Step: [1/1], Loss: 0.4781\n",
      "Epoch: [338/3000], Step: [1/1], Loss: 0.4781\n",
      "Epoch: [339/3000], Step: [1/1], Loss: 0.4780\n",
      "Epoch: [340/3000], Step: [1/1], Loss: 0.4779\n",
      "Epoch: [341/3000], Step: [1/1], Loss: 0.4778\n",
      "Epoch: [342/3000], Step: [1/1], Loss: 0.4777\n",
      "Epoch: [343/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [344/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [345/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [346/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [347/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [348/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [349/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [350/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [351/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [352/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [353/3000], Step: [1/1], Loss: 0.4778\n",
      "Epoch: [354/3000], Step: [1/1], Loss: 0.4778\n",
      "Epoch: [355/3000], Step: [1/1], Loss: 0.4778\n",
      "Epoch: [356/3000], Step: [1/1], Loss: 0.4775\n",
      "Epoch: [357/3000], Step: [1/1], Loss: 0.4773\n",
      "Epoch: [358/3000], Step: [1/1], Loss: 0.4772\n",
      "Epoch: [359/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [360/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [361/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [362/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [363/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [364/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [365/3000], Step: [1/1], Loss: 0.4772\n",
      "Epoch: [366/3000], Step: [1/1], Loss: 0.4772\n",
      "Epoch: [367/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [368/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [369/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [370/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [371/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [372/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [373/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [374/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [375/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [376/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [377/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [378/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [379/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [380/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [381/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [382/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [383/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [384/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [385/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [386/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [387/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [388/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [389/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [390/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [391/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [392/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [393/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [394/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [395/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [396/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [397/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [398/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [399/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [400/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [401/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [402/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [403/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [404/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [405/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [406/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [407/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [408/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [409/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [410/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [411/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [412/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [413/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [414/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [415/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [416/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [417/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [418/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [419/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [420/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [421/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [422/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [423/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [424/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [425/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [426/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [427/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [428/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [429/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [430/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [431/3000], Step: [1/1], Loss: 0.4748\n",
      "Epoch: [432/3000], Step: [1/1], Loss: 0.4748\n",
      "Epoch: [433/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [434/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [435/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [436/3000], Step: [1/1], Loss: 0.4748\n",
      "Epoch: [437/3000], Step: [1/1], Loss: 0.4746\n",
      "Epoch: [438/3000], Step: [1/1], Loss: 0.4746\n",
      "Epoch: [439/3000], Step: [1/1], Loss: 0.4746\n",
      "Epoch: [440/3000], Step: [1/1], Loss: 0.4746\n",
      "Epoch: [441/3000], Step: [1/1], Loss: 0.4747\n",
      "Epoch: [442/3000], Step: [1/1], Loss: 0.4747\n",
      "Epoch: [443/3000], Step: [1/1], Loss: 0.4746\n",
      "Epoch: [444/3000], Step: [1/1], Loss: 0.4745\n",
      "Epoch: [445/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [446/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [447/3000], Step: [1/1], Loss: 0.4743\n",
      "Epoch: [448/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [449/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [450/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [451/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [452/3000], Step: [1/1], Loss: 0.4743\n",
      "Epoch: [453/3000], Step: [1/1], Loss: 0.4743\n",
      "Epoch: [454/3000], Step: [1/1], Loss: 0.4742\n",
      "Epoch: [455/3000], Step: [1/1], Loss: 0.4742\n",
      "Epoch: [456/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [457/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [458/3000], Step: [1/1], Loss: 0.4741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [459/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [460/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [461/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [462/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [463/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [464/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [465/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [466/3000], Step: [1/1], Loss: 0.4740\n",
      "Epoch: [467/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [468/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [469/3000], Step: [1/1], Loss: 0.4742\n",
      "Epoch: [470/3000], Step: [1/1], Loss: 0.4742\n",
      "Epoch: [471/3000], Step: [1/1], Loss: 0.4742\n",
      "Epoch: [472/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [473/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [474/3000], Step: [1/1], Loss: 0.4739\n",
      "Epoch: [475/3000], Step: [1/1], Loss: 0.4738\n",
      "Epoch: [476/3000], Step: [1/1], Loss: 0.4737\n",
      "Epoch: [477/3000], Step: [1/1], Loss: 0.4737\n",
      "Epoch: [478/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [479/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [480/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [481/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [482/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [483/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [484/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [485/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [486/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [487/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [488/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [489/3000], Step: [1/1], Loss: 0.4737\n",
      "Epoch: [490/3000], Step: [1/1], Loss: 0.4738\n",
      "Epoch: [491/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [492/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [493/3000], Step: [1/1], Loss: 0.4742\n",
      "Epoch: [494/3000], Step: [1/1], Loss: 0.4738\n",
      "Epoch: [495/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [496/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [497/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [498/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [499/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [500/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [501/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [502/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [503/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [504/3000], Step: [1/1], Loss: 0.4737\n",
      "Epoch: [505/3000], Step: [1/1], Loss: 0.4736\n",
      "Epoch: [506/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [507/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [508/3000], Step: [1/1], Loss: 0.4731\n",
      "Epoch: [509/3000], Step: [1/1], Loss: 0.4730\n",
      "Epoch: [510/3000], Step: [1/1], Loss: 0.4729\n",
      "Epoch: [511/3000], Step: [1/1], Loss: 0.4729\n",
      "Epoch: [512/3000], Step: [1/1], Loss: 0.4729\n",
      "Epoch: [513/3000], Step: [1/1], Loss: 0.4730\n",
      "Epoch: [514/3000], Step: [1/1], Loss: 0.4730\n",
      "Epoch: [515/3000], Step: [1/1], Loss: 0.4731\n",
      "Epoch: [516/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [517/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [518/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [519/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [520/3000], Step: [1/1], Loss: 0.4731\n",
      "Epoch: [521/3000], Step: [1/1], Loss: 0.4730\n",
      "Epoch: [522/3000], Step: [1/1], Loss: 0.4729\n",
      "Epoch: [523/3000], Step: [1/1], Loss: 0.4728\n",
      "Epoch: [524/3000], Step: [1/1], Loss: 0.4727\n",
      "Epoch: [525/3000], Step: [1/1], Loss: 0.4727\n",
      "Epoch: [526/3000], Step: [1/1], Loss: 0.4727\n",
      "Epoch: [527/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [528/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [529/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [530/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [531/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [532/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [533/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [534/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [535/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [536/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [537/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [538/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [539/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [540/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [541/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [542/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [543/3000], Step: [1/1], Loss: 0.4728\n",
      "Epoch: [544/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [545/3000], Step: [1/1], Loss: 0.4734\n",
      "Epoch: [546/3000], Step: [1/1], Loss: 0.4735\n",
      "Epoch: [547/3000], Step: [1/1], Loss: 0.4731\n",
      "Epoch: [548/3000], Step: [1/1], Loss: 0.4727\n",
      "Epoch: [549/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [550/3000], Step: [1/1], Loss: 0.4722\n",
      "Epoch: [551/3000], Step: [1/1], Loss: 0.4722\n",
      "Epoch: [552/3000], Step: [1/1], Loss: 0.4723\n",
      "Epoch: [553/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [554/3000], Step: [1/1], Loss: 0.4727\n",
      "Epoch: [555/3000], Step: [1/1], Loss: 0.4730\n",
      "Epoch: [556/3000], Step: [1/1], Loss: 0.4730\n",
      "Epoch: [557/3000], Step: [1/1], Loss: 0.4729\n",
      "Epoch: [558/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [559/3000], Step: [1/1], Loss: 0.4721\n",
      "Epoch: [560/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [561/3000], Step: [1/1], Loss: 0.4721\n",
      "Epoch: [562/3000], Step: [1/1], Loss: 0.4723\n",
      "Epoch: [563/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [564/3000], Step: [1/1], Loss: 0.4729\n",
      "Epoch: [565/3000], Step: [1/1], Loss: 0.4727\n",
      "Epoch: [566/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [567/3000], Step: [1/1], Loss: 0.4722\n",
      "Epoch: [568/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [569/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [570/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [571/3000], Step: [1/1], Loss: 0.4722\n",
      "Epoch: [572/3000], Step: [1/1], Loss: 0.4724\n",
      "Epoch: [573/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [574/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [575/3000], Step: [1/1], Loss: 0.4723\n",
      "Epoch: [576/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [577/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [578/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [579/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [580/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [581/3000], Step: [1/1], Loss: 0.4721\n",
      "Epoch: [582/3000], Step: [1/1], Loss: 0.4723\n",
      "Epoch: [583/3000], Step: [1/1], Loss: 0.4722\n",
      "Epoch: [584/3000], Step: [1/1], Loss: 0.4721\n",
      "Epoch: [585/3000], Step: [1/1], Loss: 0.4719\n",
      "Epoch: [586/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [587/3000], Step: [1/1], Loss: 0.4716\n",
      "Epoch: [588/3000], Step: [1/1], Loss: 0.4716\n",
      "Epoch: [589/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [590/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [591/3000], Step: [1/1], Loss: 0.4719\n",
      "Epoch: [592/3000], Step: [1/1], Loss: 0.4720\n",
      "Epoch: [593/3000], Step: [1/1], Loss: 0.4719\n",
      "Epoch: [594/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [595/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [596/3000], Step: [1/1], Loss: 0.4716\n",
      "Epoch: [597/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [598/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [599/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [600/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [601/3000], Step: [1/1], Loss: 0.4716\n",
      "Epoch: [602/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [603/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [604/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [605/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [606/3000], Step: [1/1], Loss: 0.4716\n",
      "Epoch: [607/3000], Step: [1/1], Loss: 0.4714\n",
      "Epoch: [608/3000], Step: [1/1], Loss: 0.4714\n",
      "Epoch: [609/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [610/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [611/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [612/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [613/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [614/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [615/3000], Step: [1/1], Loss: 0.4714\n",
      "Epoch: [616/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [617/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [618/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [619/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [620/3000], Step: [1/1], Loss: 0.4715\n",
      "Epoch: [621/3000], Step: [1/1], Loss: 0.4714\n",
      "Epoch: [622/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [623/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [624/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [625/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [626/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [627/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [628/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [629/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [630/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [631/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [632/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [633/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [634/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [635/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [636/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [637/3000], Step: [1/1], Loss: 0.4714\n",
      "Epoch: [638/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [639/3000], Step: [1/1], Loss: 0.4714\n",
      "Epoch: [640/3000], Step: [1/1], Loss: 0.4713\n",
      "Epoch: [641/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [642/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [643/3000], Step: [1/1], Loss: 0.4710\n",
      "Epoch: [644/3000], Step: [1/1], Loss: 0.4710\n",
      "Epoch: [645/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [646/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [647/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [648/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [649/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [650/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [651/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [652/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [653/3000], Step: [1/1], Loss: 0.4710\n",
      "Epoch: [654/3000], Step: [1/1], Loss: 0.4710\n",
      "Epoch: [655/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [656/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [657/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [658/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [659/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [660/3000], Step: [1/1], Loss: 0.4710\n",
      "Epoch: [661/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [662/3000], Step: [1/1], Loss: 0.4708\n",
      "Epoch: [663/3000], Step: [1/1], Loss: 0.4707\n",
      "Epoch: [664/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [665/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [666/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [667/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [668/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [669/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [670/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [671/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [672/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [673/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [674/3000], Step: [1/1], Loss: 0.4707\n",
      "Epoch: [675/3000], Step: [1/1], Loss: 0.4708\n",
      "Epoch: [676/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [677/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [678/3000], Step: [1/1], Loss: 0.4711\n",
      "Epoch: [679/3000], Step: [1/1], Loss: 0.4712\n",
      "Epoch: [680/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [681/3000], Step: [1/1], Loss: 0.4708\n",
      "Epoch: [682/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [683/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [684/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [685/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [686/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [687/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [688/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [689/3000], Step: [1/1], Loss: 0.4703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [690/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [691/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [692/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [693/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [694/3000], Step: [1/1], Loss: 0.4707\n",
      "Epoch: [695/3000], Step: [1/1], Loss: 0.4708\n",
      "Epoch: [696/3000], Step: [1/1], Loss: 0.4710\n",
      "Epoch: [697/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [698/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [699/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [700/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [701/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [702/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [703/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [704/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [705/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [706/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [707/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [708/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [709/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [710/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [711/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [712/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [713/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [714/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [715/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [716/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [717/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [718/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [719/3000], Step: [1/1], Loss: 0.4709\n",
      "Epoch: [720/3000], Step: [1/1], Loss: 0.4708\n",
      "Epoch: [721/3000], Step: [1/1], Loss: 0.4707\n",
      "Epoch: [722/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [723/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [724/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [725/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [726/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [727/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [728/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [729/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [730/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [731/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [732/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [733/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [734/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [735/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [736/3000], Step: [1/1], Loss: 0.4700\n",
      "Epoch: [737/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [738/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [739/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [740/3000], Step: [1/1], Loss: 0.4706\n",
      "Epoch: [741/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [742/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [743/3000], Step: [1/1], Loss: 0.4701\n",
      "Epoch: [744/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [745/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [746/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [747/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [748/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [749/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [750/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [751/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [752/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [753/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [754/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [755/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [756/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [757/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [758/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [759/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [760/3000], Step: [1/1], Loss: 0.4703\n",
      "Epoch: [761/3000], Step: [1/1], Loss: 0.4704\n",
      "Epoch: [762/3000], Step: [1/1], Loss: 0.4707\n",
      "Epoch: [763/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [764/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [765/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [766/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [767/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [768/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [769/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [770/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [771/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [772/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [773/3000], Step: [1/1], Loss: 0.4705\n",
      "Epoch: [774/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [775/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [776/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [777/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [778/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [779/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [780/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [781/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [782/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [783/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [784/3000], Step: [1/1], Loss: 0.4702\n",
      "Epoch: [785/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [786/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [787/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [788/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [789/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [790/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [791/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [792/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [793/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [794/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [795/3000], Step: [1/1], Loss: 0.4699\n",
      "Epoch: [796/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [797/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [798/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [799/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [800/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [801/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [802/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [803/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [804/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [805/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [806/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [807/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [808/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [809/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [810/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [811/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [812/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [813/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [814/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [815/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [816/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [817/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [818/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [819/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [820/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [821/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [822/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [823/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [824/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [825/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [826/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [827/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [828/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [829/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [830/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [831/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [832/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [833/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [834/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [835/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [836/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [837/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [838/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [839/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [840/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [841/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [842/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [843/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [844/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [845/3000], Step: [1/1], Loss: 0.4695\n",
      "Epoch: [846/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [847/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [848/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [849/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [850/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [851/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [852/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [853/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [854/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [855/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [856/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [857/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [858/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [859/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [860/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [861/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [862/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [863/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [864/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [865/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [866/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [867/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [868/3000], Step: [1/1], Loss: 0.4697\n",
      "Epoch: [869/3000], Step: [1/1], Loss: 0.4694\n",
      "Epoch: [870/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [871/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [872/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [873/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [874/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [875/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [876/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [877/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [878/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [879/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [880/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [881/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [882/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [883/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [884/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [885/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [886/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [887/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [888/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [889/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [890/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [891/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [892/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [893/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [894/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [895/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [896/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [897/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [898/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [899/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [900/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [901/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [902/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [903/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [904/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [905/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [906/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [907/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [908/3000], Step: [1/1], Loss: 0.4691\n",
      "Epoch: [909/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [910/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [911/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [912/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [913/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [914/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [915/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [916/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [917/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [918/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [919/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [920/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [921/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [922/3000], Step: [1/1], Loss: 0.4684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [923/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [924/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [925/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [926/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [927/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [928/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [929/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [930/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [931/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [932/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [933/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [934/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [935/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [936/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [937/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [938/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [939/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [940/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [941/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [942/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [943/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [944/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [945/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [946/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [947/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [948/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [949/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [950/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [951/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [952/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [953/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [954/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [955/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [956/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [957/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [958/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [959/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [960/3000], Step: [1/1], Loss: 0.4693\n",
      "Epoch: [961/3000], Step: [1/1], Loss: 0.4696\n",
      "Epoch: [962/3000], Step: [1/1], Loss: 0.4689\n",
      "Epoch: [963/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [964/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [965/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [966/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [967/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [968/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [969/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [970/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [971/3000], Step: [1/1], Loss: 0.4688\n",
      "Epoch: [972/3000], Step: [1/1], Loss: 0.4690\n",
      "Epoch: [973/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [974/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [975/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [976/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [977/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [978/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [979/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [980/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [981/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [982/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [983/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [984/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [985/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [986/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [987/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [988/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [989/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [990/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [991/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [992/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [993/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [994/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [995/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [996/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [997/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [998/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [999/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [1000/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1001/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1002/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1003/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1004/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1005/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1006/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1007/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1008/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1009/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1010/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1011/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1012/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1013/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1014/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1015/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1016/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [1017/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1018/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1019/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1020/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [1021/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1022/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1023/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1024/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1025/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1026/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1027/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1028/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1029/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1030/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1031/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1032/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1033/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1034/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1035/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1036/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1037/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1038/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1039/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1040/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1041/3000], Step: [1/1], Loss: 0.4680\n",
      "Epoch: [1042/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [1043/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1044/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1045/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1046/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1047/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1048/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1049/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1050/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1051/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1052/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1053/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1054/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1055/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1056/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1057/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1058/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1059/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1060/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1061/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1062/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1063/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1064/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1065/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1066/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1067/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1068/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1069/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1070/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1071/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1072/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1073/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1074/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1075/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1076/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1077/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1078/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1079/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1080/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1081/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1082/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1083/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1084/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1085/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1086/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1087/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1088/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1089/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1090/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1091/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1092/3000], Step: [1/1], Loss: 0.4685\n",
      "Epoch: [1093/3000], Step: [1/1], Loss: 0.4683\n",
      "Epoch: [1094/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1095/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1096/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1097/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1098/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1099/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1100/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1101/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1102/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1103/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1104/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1105/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1106/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1107/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1108/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1109/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1110/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1111/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1112/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1113/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1114/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1115/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1116/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1117/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1118/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1119/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1120/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1121/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1122/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1123/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1124/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1125/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1126/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1127/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1128/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1129/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1130/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1131/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1132/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1133/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1134/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1135/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1136/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1137/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1138/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1139/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1140/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1141/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1142/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1143/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1144/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1145/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1146/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1147/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1148/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1149/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1150/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1151/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1152/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1153/3000], Step: [1/1], Loss: 0.4677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1154/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1155/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1156/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1157/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1158/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1159/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1160/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1161/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1162/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1163/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1164/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1165/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1166/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1167/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1168/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1169/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1170/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1171/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1172/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1173/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1174/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1175/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1176/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1177/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1178/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1179/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1180/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1181/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1182/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1183/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1184/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1185/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1186/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1187/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1188/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1189/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1190/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1191/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1192/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1193/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1194/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1195/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1196/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1197/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1198/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1199/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1200/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1201/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1202/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1203/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1204/3000], Step: [1/1], Loss: 0.4682\n",
      "Epoch: [1205/3000], Step: [1/1], Loss: 0.4684\n",
      "Epoch: [1206/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1207/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1208/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1209/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1210/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1211/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1212/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1213/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1214/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1215/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1216/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1217/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1218/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1219/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1220/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1221/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1222/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1223/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1224/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1225/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1226/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1227/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1228/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1229/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1230/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1231/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1232/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1233/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1234/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1235/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1236/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1237/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1238/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1239/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1240/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1241/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1242/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1243/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1244/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1245/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1246/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1247/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1248/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1249/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1250/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1251/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1252/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1253/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1254/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1255/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1256/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1257/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1258/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1259/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1260/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1261/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1262/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1263/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1264/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1265/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1266/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1267/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1268/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1269/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1270/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1271/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1272/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1273/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1274/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1275/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1276/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1277/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1278/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1279/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1280/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1281/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1282/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1283/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1284/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1285/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1286/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1287/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1288/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1289/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1290/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1291/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1292/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1293/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1294/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1295/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1296/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1297/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1298/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1299/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1300/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1301/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1302/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1303/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1304/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1305/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1306/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1307/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1308/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1309/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1310/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1311/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1312/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1313/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1314/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1315/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1316/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1317/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1318/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1319/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1320/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1321/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1322/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1323/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1324/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1325/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1326/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1327/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1328/3000], Step: [1/1], Loss: 0.4677\n",
      "Epoch: [1329/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1330/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1331/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1332/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1333/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1334/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1335/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1336/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1337/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1338/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1339/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1340/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1341/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1342/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1343/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1344/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1345/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1346/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1347/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1348/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1349/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1350/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1351/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1352/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1353/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1354/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1355/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1356/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1357/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1358/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1359/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1360/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1361/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1362/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1363/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1364/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1365/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1366/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1367/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1368/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1369/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1370/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1371/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1372/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1373/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1374/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1375/3000], Step: [1/1], Loss: 0.4658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1376/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1377/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1378/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1379/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1380/3000], Step: [1/1], Loss: 0.4674\n",
      "Epoch: [1381/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1382/3000], Step: [1/1], Loss: 0.4672\n",
      "Epoch: [1383/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1384/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1385/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1386/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1387/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1388/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1389/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1390/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1391/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1392/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1393/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1394/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1395/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1396/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1397/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1398/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1399/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1400/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1401/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1402/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1403/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1404/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1405/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1406/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1407/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1408/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1409/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1410/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1411/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1412/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1413/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1414/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1415/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1416/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1417/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1418/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1419/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1420/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1421/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1422/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1423/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1424/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1425/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1426/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1427/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1428/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1429/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1430/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1431/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1432/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1433/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1434/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1435/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1436/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1437/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1438/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1439/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1440/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1441/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1442/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1443/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1444/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1445/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1446/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1447/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1448/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1449/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1450/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1451/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1452/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1453/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1454/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1455/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1456/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1457/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1458/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1459/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1460/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1461/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1462/3000], Step: [1/1], Loss: 0.4667\n",
      "Epoch: [1463/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1464/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1465/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1466/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1467/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1468/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1469/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1470/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1471/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1472/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1473/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1474/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1475/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1476/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1477/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1478/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1479/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1480/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1481/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1482/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1483/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1484/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1485/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1486/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1487/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1488/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1489/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1490/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1491/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1492/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1493/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1494/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1495/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1496/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1497/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1498/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1499/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1500/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1501/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1502/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1503/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1504/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1505/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1506/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1507/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1508/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1509/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1510/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1511/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1512/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1513/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1514/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1515/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1516/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1517/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1518/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1519/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1520/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1521/3000], Step: [1/1], Loss: 0.4668\n",
      "Epoch: [1522/3000], Step: [1/1], Loss: 0.4670\n",
      "Epoch: [1523/3000], Step: [1/1], Loss: 0.4675\n",
      "Epoch: [1524/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1525/3000], Step: [1/1], Loss: 0.4660\n",
      "Epoch: [1526/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1527/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1528/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1529/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1530/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1531/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1532/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1533/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1534/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1535/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1536/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1537/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1538/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1539/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1540/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1541/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1542/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1543/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1544/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1545/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1546/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1547/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1548/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1549/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1550/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1551/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1552/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1553/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1554/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1555/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1556/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1557/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1558/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1559/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1560/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1561/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1562/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1563/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1564/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1565/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1566/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1567/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1568/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1569/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1570/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1571/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1572/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1573/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1574/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1575/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1576/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1577/3000], Step: [1/1], Loss: 0.4671\n",
      "Epoch: [1578/3000], Step: [1/1], Loss: 0.4665\n",
      "Epoch: [1579/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1580/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1581/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1582/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1583/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1584/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1585/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1586/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1587/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1588/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1589/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1590/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1591/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1592/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1593/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1594/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1595/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1596/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1597/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1598/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1599/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1600/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1601/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1602/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1603/3000], Step: [1/1], Loss: 0.4648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1604/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1605/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1606/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1607/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1608/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1609/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1610/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1611/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1612/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1613/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1614/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1615/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1616/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1617/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1618/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1619/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1620/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1621/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1622/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1623/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1624/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1625/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1626/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1627/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1628/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1629/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1630/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1631/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1632/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1633/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1634/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1635/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1636/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1637/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1638/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1639/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1640/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1641/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1642/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1643/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1644/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1645/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1646/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1647/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1648/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1649/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1650/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1651/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1652/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1653/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1654/3000], Step: [1/1], Loss: 0.4676\n",
      "Epoch: [1655/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1656/3000], Step: [1/1], Loss: 0.4687\n",
      "Epoch: [1657/3000], Step: [1/1], Loss: 0.4659\n",
      "Epoch: [1658/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1659/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1660/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1661/3000], Step: [1/1], Loss: 0.4679\n",
      "Epoch: [1662/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1663/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1664/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1665/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1666/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1667/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1668/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1669/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1670/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1671/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1672/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1673/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1674/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1675/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1676/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1677/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1678/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1679/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1680/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1681/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1682/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1683/3000], Step: [1/1], Loss: 0.4648\n",
      "Epoch: [1684/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1685/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1686/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1687/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1688/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1689/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1690/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1691/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1692/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1693/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1694/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1695/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1696/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1697/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1698/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1699/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1700/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1701/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1702/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1703/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1704/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1705/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1706/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1707/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1708/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1709/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1710/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1711/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1712/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1713/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1714/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1715/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1716/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1717/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1718/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1719/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1720/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1721/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1722/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1723/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1724/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1725/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1726/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1727/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1728/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1729/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1730/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1731/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1732/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1733/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1734/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1735/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1736/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1737/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1738/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1739/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1740/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1741/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1742/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1743/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1744/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1745/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1746/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1747/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1748/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1749/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1750/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1751/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1752/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1753/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1754/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1755/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1756/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1757/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1758/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1759/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1760/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1761/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1762/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1763/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1764/3000], Step: [1/1], Loss: 0.4657\n",
      "Epoch: [1765/3000], Step: [1/1], Loss: 0.4669\n",
      "Epoch: [1766/3000], Step: [1/1], Loss: 0.4698\n",
      "Epoch: [1767/3000], Step: [1/1], Loss: 0.4652\n",
      "Epoch: [1768/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1769/3000], Step: [1/1], Loss: 0.4678\n",
      "Epoch: [1770/3000], Step: [1/1], Loss: 0.4681\n",
      "Epoch: [1771/3000], Step: [1/1], Loss: 0.4686\n",
      "Epoch: [1772/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1773/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1774/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1775/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1776/3000], Step: [1/1], Loss: 0.4661\n",
      "Epoch: [1777/3000], Step: [1/1], Loss: 0.4656\n",
      "Epoch: [1778/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1779/3000], Step: [1/1], Loss: 0.4651\n",
      "Epoch: [1780/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1781/3000], Step: [1/1], Loss: 0.4655\n",
      "Epoch: [1782/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1783/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1784/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1785/3000], Step: [1/1], Loss: 0.4654\n",
      "Epoch: [1786/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1787/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1788/3000], Step: [1/1], Loss: 0.4645\n",
      "Epoch: [1789/3000], Step: [1/1], Loss: 0.4649\n",
      "Epoch: [1790/3000], Step: [1/1], Loss: 0.4647\n",
      "Epoch: [1791/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1792/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1793/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1794/3000], Step: [1/1], Loss: 0.4646\n",
      "Epoch: [1795/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1796/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1797/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1798/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1799/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1800/3000], Step: [1/1], Loss: 0.4643\n",
      "Epoch: [1801/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1802/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1803/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1804/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1805/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1806/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1807/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1808/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1809/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1810/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1811/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1812/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1813/3000], Step: [1/1], Loss: 0.4642\n",
      "Epoch: [1814/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1815/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1816/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1817/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1818/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1819/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1820/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1821/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1822/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1823/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1824/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1825/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1826/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1827/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1828/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1829/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1830/3000], Step: [1/1], Loss: 0.4640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1831/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1832/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1833/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1834/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1835/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1836/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1837/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1838/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1839/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1840/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1841/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1842/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1843/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1844/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1845/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1846/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1847/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1848/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1849/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1850/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1851/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1852/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1853/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1854/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1855/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1856/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1857/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1858/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1859/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1860/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1861/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1862/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1863/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1864/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1865/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1866/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1867/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1868/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1869/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1870/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1871/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1872/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1873/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1874/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1875/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1876/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1877/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1878/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1879/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1880/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1881/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1882/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1883/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1884/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1885/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1886/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1887/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1888/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1889/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1890/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1891/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1892/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1893/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1894/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1895/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1896/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1897/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1898/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1899/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1900/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1901/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1902/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1903/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1904/3000], Step: [1/1], Loss: 0.4638\n",
      "Epoch: [1905/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1906/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1907/3000], Step: [1/1], Loss: 0.4639\n",
      "Epoch: [1908/3000], Step: [1/1], Loss: 0.4640\n",
      "Epoch: [1909/3000], Step: [1/1], Loss: 0.4641\n",
      "Epoch: [1910/3000], Step: [1/1], Loss: 0.4644\n",
      "Epoch: [1911/3000], Step: [1/1], Loss: 0.4650\n",
      "Epoch: [1912/3000], Step: [1/1], Loss: 0.4666\n",
      "Epoch: [1913/3000], Step: [1/1], Loss: 0.4692\n",
      "Epoch: [1914/3000], Step: [1/1], Loss: 0.4718\n",
      "Epoch: [1915/3000], Step: [1/1], Loss: 0.4663\n",
      "Epoch: [1916/3000], Step: [1/1], Loss: 0.4795\n",
      "Epoch: [1917/3000], Step: [1/1], Loss: 0.4820\n",
      "Epoch: [1918/3000], Step: [1/1], Loss: 0.4811\n",
      "Epoch: [1919/3000], Step: [1/1], Loss: 0.4800\n",
      "Epoch: [1920/3000], Step: [1/1], Loss: 0.4826\n",
      "Epoch: [1921/3000], Step: [1/1], Loss: 0.4744\n",
      "Epoch: [1922/3000], Step: [1/1], Loss: 0.4662\n",
      "Epoch: [1923/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [1924/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [1925/3000], Step: [1/1], Loss: 0.4807\n",
      "Epoch: [1926/3000], Step: [1/1], Loss: 0.4792\n",
      "Epoch: [1927/3000], Step: [1/1], Loss: 0.4747\n",
      "Epoch: [1928/3000], Step: [1/1], Loss: 0.4658\n",
      "Epoch: [1929/3000], Step: [1/1], Loss: 0.4673\n",
      "Epoch: [1930/3000], Step: [1/1], Loss: 0.4802\n",
      "Epoch: [1931/3000], Step: [1/1], Loss: 0.4653\n",
      "Epoch: [1932/3000], Step: [1/1], Loss: 0.4874\n",
      "Epoch: [1933/3000], Step: [1/1], Loss: 0.4900\n",
      "Epoch: [1934/3000], Step: [1/1], Loss: 0.4839\n",
      "Epoch: [1935/3000], Step: [1/1], Loss: 0.4873\n",
      "Epoch: [1936/3000], Step: [1/1], Loss: 0.4889\n",
      "Epoch: [1937/3000], Step: [1/1], Loss: 0.4917\n",
      "Epoch: [1938/3000], Step: [1/1], Loss: 0.4926\n",
      "Epoch: [1939/3000], Step: [1/1], Loss: 0.4915\n",
      "Epoch: [1940/3000], Step: [1/1], Loss: 0.4937\n",
      "Epoch: [1941/3000], Step: [1/1], Loss: 0.4913\n",
      "Epoch: [1942/3000], Step: [1/1], Loss: 0.4905\n",
      "Epoch: [1943/3000], Step: [1/1], Loss: 0.4908\n",
      "Epoch: [1944/3000], Step: [1/1], Loss: 0.4907\n",
      "Epoch: [1945/3000], Step: [1/1], Loss: 0.4882\n",
      "Epoch: [1946/3000], Step: [1/1], Loss: 0.4860\n",
      "Epoch: [1947/3000], Step: [1/1], Loss: 0.4791\n",
      "Epoch: [1948/3000], Step: [1/1], Loss: 0.4893\n",
      "Epoch: [1949/3000], Step: [1/1], Loss: 0.4905\n",
      "Epoch: [1950/3000], Step: [1/1], Loss: 0.4844\n",
      "Epoch: [1951/3000], Step: [1/1], Loss: 0.4866\n",
      "Epoch: [1952/3000], Step: [1/1], Loss: 0.4898\n",
      "Epoch: [1953/3000], Step: [1/1], Loss: 0.4868\n",
      "Epoch: [1954/3000], Step: [1/1], Loss: 0.4794\n",
      "Epoch: [1955/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [1956/3000], Step: [1/1], Loss: 0.4726\n",
      "Epoch: [1957/3000], Step: [1/1], Loss: 0.4721\n",
      "Epoch: [1958/3000], Step: [1/1], Loss: 0.4732\n",
      "Epoch: [1959/3000], Step: [1/1], Loss: 0.4788\n",
      "Epoch: [1960/3000], Step: [1/1], Loss: 0.4829\n",
      "Epoch: [1961/3000], Step: [1/1], Loss: 0.4838\n",
      "Epoch: [1962/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [1963/3000], Step: [1/1], Loss: 0.4884\n",
      "Epoch: [1964/3000], Step: [1/1], Loss: 0.4921\n",
      "Epoch: [1965/3000], Step: [1/1], Loss: 0.4819\n",
      "Epoch: [1966/3000], Step: [1/1], Loss: 0.4850\n",
      "Epoch: [1967/3000], Step: [1/1], Loss: 0.4728\n",
      "Epoch: [1968/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [1969/3000], Step: [1/1], Loss: 0.4807\n",
      "Epoch: [1970/3000], Step: [1/1], Loss: 0.4801\n",
      "Epoch: [1971/3000], Step: [1/1], Loss: 0.4733\n",
      "Epoch: [1972/3000], Step: [1/1], Loss: 0.4664\n",
      "Epoch: [1973/3000], Step: [1/1], Loss: 0.4790\n",
      "Epoch: [1974/3000], Step: [1/1], Loss: 0.4725\n",
      "Epoch: [1975/3000], Step: [1/1], Loss: 0.4717\n",
      "Epoch: [1976/3000], Step: [1/1], Loss: 0.4741\n",
      "Epoch: [1977/3000], Step: [1/1], Loss: 0.4707\n",
      "Epoch: [1978/3000], Step: [1/1], Loss: 0.4834\n",
      "Epoch: [1979/3000], Step: [1/1], Loss: 0.4807\n",
      "Epoch: [1980/3000], Step: [1/1], Loss: 0.4857\n",
      "Epoch: [1981/3000], Step: [1/1], Loss: 0.4950\n",
      "Epoch: [1982/3000], Step: [1/1], Loss: 0.4866\n",
      "Epoch: [1983/3000], Step: [1/1], Loss: 0.4842\n",
      "Epoch: [1984/3000], Step: [1/1], Loss: 0.4878\n",
      "Epoch: [1985/3000], Step: [1/1], Loss: 0.4916\n",
      "Epoch: [1986/3000], Step: [1/1], Loss: 0.4846\n",
      "Epoch: [1987/3000], Step: [1/1], Loss: 0.4842\n",
      "Epoch: [1988/3000], Step: [1/1], Loss: 0.4878\n",
      "Epoch: [1989/3000], Step: [1/1], Loss: 0.4883\n",
      "Epoch: [1990/3000], Step: [1/1], Loss: 0.4791\n",
      "Epoch: [1991/3000], Step: [1/1], Loss: 0.4879\n",
      "Epoch: [1992/3000], Step: [1/1], Loss: 0.4777\n",
      "Epoch: [1993/3000], Step: [1/1], Loss: 0.4838\n",
      "Epoch: [1994/3000], Step: [1/1], Loss: 0.4819\n",
      "Epoch: [1995/3000], Step: [1/1], Loss: 0.4825\n",
      "Epoch: [1996/3000], Step: [1/1], Loss: 0.4784\n",
      "Epoch: [1997/3000], Step: [1/1], Loss: 0.4806\n",
      "Epoch: [1998/3000], Step: [1/1], Loss: 0.4785\n",
      "Epoch: [1999/3000], Step: [1/1], Loss: 0.4792\n",
      "Epoch: [2000/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [2001/3000], Step: [1/1], Loss: 0.4784\n",
      "Epoch: [2002/3000], Step: [1/1], Loss: 0.4780\n",
      "Epoch: [2003/3000], Step: [1/1], Loss: 0.4777\n",
      "Epoch: [2004/3000], Step: [1/1], Loss: 0.4779\n",
      "Epoch: [2005/3000], Step: [1/1], Loss: 0.4774\n",
      "Epoch: [2006/3000], Step: [1/1], Loss: 0.4780\n",
      "Epoch: [2007/3000], Step: [1/1], Loss: 0.4772\n",
      "Epoch: [2008/3000], Step: [1/1], Loss: 0.4780\n",
      "Epoch: [2009/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [2010/3000], Step: [1/1], Loss: 0.4776\n",
      "Epoch: [2011/3000], Step: [1/1], Loss: 0.4772\n",
      "Epoch: [2012/3000], Step: [1/1], Loss: 0.4772\n",
      "Epoch: [2013/3000], Step: [1/1], Loss: 0.4773\n",
      "Epoch: [2014/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2015/3000], Step: [1/1], Loss: 0.4773\n",
      "Epoch: [2016/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2017/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [2018/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2019/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2020/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [2021/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2022/3000], Step: [1/1], Loss: 0.4771\n",
      "Epoch: [2023/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2024/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2025/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2026/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2027/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2028/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2029/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2030/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2031/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2032/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2033/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2034/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2035/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2036/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2037/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2038/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2039/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2040/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2041/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2042/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2043/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2044/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2045/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2046/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2047/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2048/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2049/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2050/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2051/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2052/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2053/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2054/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2055/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2056/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2057/3000], Step: [1/1], Loss: 0.4767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2058/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2059/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2060/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2061/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2062/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2063/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2064/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2065/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2066/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2067/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2068/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2069/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2070/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2071/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2072/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2073/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2074/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2075/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2076/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2077/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2078/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2079/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2080/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2081/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2082/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2083/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2084/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2085/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2086/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2087/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2088/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2089/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2090/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2091/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2092/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2093/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2094/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2095/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2096/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2097/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2098/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2099/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2100/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2101/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2102/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2103/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2104/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2105/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2106/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2107/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2108/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2109/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2110/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2111/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2112/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2113/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2114/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2115/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2116/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2117/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2118/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2119/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2120/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2121/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2122/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2123/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2124/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2125/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2126/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2127/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2128/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2129/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2130/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2131/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2132/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2133/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2134/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2135/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2136/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2137/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2138/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2139/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2140/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2141/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2142/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2143/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2144/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2145/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2146/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2147/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2148/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2149/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2150/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2151/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2152/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2153/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2154/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2155/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2156/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2157/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2158/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2159/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2160/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2161/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2162/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2163/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2164/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2165/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2166/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2167/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2168/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2169/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2170/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2171/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2172/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2173/3000], Step: [1/1], Loss: 0.4768\n",
      "Epoch: [2174/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2175/3000], Step: [1/1], Loss: 0.4770\n",
      "Epoch: [2176/3000], Step: [1/1], Loss: 0.4769\n",
      "Epoch: [2177/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2178/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2179/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2180/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2181/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2182/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2183/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2184/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2185/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2186/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2187/3000], Step: [1/1], Loss: 0.4767\n",
      "Epoch: [2188/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2189/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2190/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2191/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2192/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2193/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2194/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2195/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2196/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2197/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2198/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2199/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2200/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2201/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2202/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2203/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2204/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2205/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2206/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2207/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2208/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2209/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2210/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2211/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2212/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2213/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2214/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2215/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2216/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2217/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2218/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2219/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2220/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2221/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2222/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2223/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2224/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2225/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2226/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2227/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2228/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2229/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2230/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2231/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2232/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2233/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2234/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2235/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2236/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2237/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2238/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2239/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2240/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2241/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2242/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2243/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2244/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2245/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2246/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2247/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2248/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2249/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2250/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2251/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2252/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2253/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2254/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2255/3000], Step: [1/1], Loss: 0.4766\n",
      "Epoch: [2256/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2257/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2258/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2259/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2260/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2261/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2262/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2263/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2264/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2265/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2266/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2267/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2268/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2269/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2270/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2271/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2272/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2273/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2274/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2275/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2276/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2277/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2278/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2279/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2280/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2281/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2282/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2283/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2284/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2285/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2286/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2287/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2288/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2289/3000], Step: [1/1], Loss: 0.4761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2290/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2291/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2292/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2293/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2294/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2295/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2296/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2297/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2298/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2299/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2300/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2301/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2302/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2303/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2304/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2305/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2306/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2307/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2308/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2309/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2310/3000], Step: [1/1], Loss: 0.4765\n",
      "Epoch: [2311/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2312/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2313/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2314/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2315/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2316/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2317/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2318/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2319/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2320/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2321/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2322/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2323/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2324/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2325/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2326/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2327/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2328/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2329/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2330/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2331/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2332/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2333/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2334/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2335/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2336/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2337/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2338/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2339/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2340/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2341/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2342/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2343/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2344/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2345/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2346/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2347/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2348/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2349/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2350/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2351/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2352/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2353/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2354/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2355/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2356/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2357/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2358/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2359/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2360/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2361/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2362/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2363/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2364/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2365/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2366/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2367/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2368/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2369/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2370/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2371/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2372/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2373/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2374/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2375/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2376/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2377/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2378/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2379/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2380/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2381/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2382/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2383/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2384/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2385/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2386/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2387/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2388/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2389/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2390/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2391/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2392/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2393/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2394/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2395/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2396/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2397/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2398/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2399/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2400/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2401/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2402/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2403/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2404/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2405/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2406/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2407/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2408/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2409/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2410/3000], Step: [1/1], Loss: 0.4764\n",
      "Epoch: [2411/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2412/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2413/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2414/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2415/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2416/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2417/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2418/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2419/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2420/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2421/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2422/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2423/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2424/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2425/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2426/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2427/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2428/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2429/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2430/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2431/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2432/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2433/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2434/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2435/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2436/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2437/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2438/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2439/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2440/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2441/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2442/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2443/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2444/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2445/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2446/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2447/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2448/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2449/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2450/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2451/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2452/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2453/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2454/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2455/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2456/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2457/3000], Step: [1/1], Loss: 0.4763\n",
      "Epoch: [2458/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2459/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2460/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2461/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2462/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2463/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2464/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2465/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2466/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2467/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2468/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2469/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2470/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2471/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2472/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2473/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2474/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2475/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2476/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2477/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2478/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2479/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2480/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2481/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2482/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2483/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2484/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2485/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2486/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2487/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2488/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2489/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2490/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2491/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2492/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2493/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2494/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2495/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2496/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2497/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2498/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2499/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2500/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2501/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2502/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2503/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2504/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2505/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2506/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2507/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2508/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2509/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2510/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2511/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2512/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2513/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2514/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2515/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2516/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2517/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2518/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2519/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2520/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2521/3000], Step: [1/1], Loss: 0.4757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2522/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2523/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2524/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2525/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2526/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2527/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2528/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2529/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2530/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2531/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2532/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2533/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2534/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2535/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2536/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2537/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2538/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2539/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2540/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2541/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2542/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2543/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2544/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2545/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2546/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2547/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2548/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2549/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2550/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2551/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2552/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2553/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2554/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2555/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2556/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2557/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2558/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2559/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2560/3000], Step: [1/1], Loss: 0.4760\n",
      "Epoch: [2561/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2562/3000], Step: [1/1], Loss: 0.4762\n",
      "Epoch: [2563/3000], Step: [1/1], Loss: 0.4761\n",
      "Epoch: [2564/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2565/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2566/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2567/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2568/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2569/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2570/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2571/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2572/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2573/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2574/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2575/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2576/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2577/3000], Step: [1/1], Loss: 0.4759\n",
      "Epoch: [2578/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2579/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2580/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2581/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2582/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2583/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2584/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2585/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2586/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2587/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2588/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2589/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2590/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2591/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2592/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2593/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2594/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2595/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2596/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2597/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2598/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2599/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2600/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2601/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2602/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2603/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2604/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2605/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2606/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2607/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2608/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2609/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2610/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2611/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2612/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2613/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2614/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2615/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2616/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2617/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2618/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2619/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2620/3000], Step: [1/1], Loss: 0.4758\n",
      "Epoch: [2621/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2622/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2623/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2624/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2625/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2626/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2627/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2628/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2629/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2630/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2631/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2632/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2633/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2634/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2635/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2636/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2637/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2638/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2639/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2640/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2641/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2642/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2643/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2644/3000], Step: [1/1], Loss: 0.4757\n",
      "Epoch: [2645/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2646/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2647/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2648/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2649/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2650/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2651/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2652/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2653/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2654/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2655/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2656/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2657/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2658/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2659/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2660/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2661/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2662/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2663/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2664/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2665/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2666/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2667/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2668/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2669/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2670/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2671/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2672/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2673/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2674/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2675/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2676/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2677/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2678/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2679/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2680/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2681/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2682/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2683/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2684/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2685/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2686/3000], Step: [1/1], Loss: 0.4756\n",
      "Epoch: [2687/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2688/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2689/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2690/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2691/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2692/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2693/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2694/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2695/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2696/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2697/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2698/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2699/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2700/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2701/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2702/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2703/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2704/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2705/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2706/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2707/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2708/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2709/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2710/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2711/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2712/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2713/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2714/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2715/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2716/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2717/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2718/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2719/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2720/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2721/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2722/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2723/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2724/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2725/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2726/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2727/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2728/3000], Step: [1/1], Loss: 0.4755\n",
      "Epoch: [2729/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2730/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2731/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2732/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2733/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2734/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2735/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2736/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2737/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2738/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2739/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2740/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2741/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2742/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2743/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2744/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2745/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2746/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2747/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2748/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2749/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2750/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2751/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2752/3000], Step: [1/1], Loss: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2753/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2754/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2755/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2756/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2757/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2758/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2759/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2760/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2761/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2762/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2763/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2764/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2765/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2766/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2767/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2768/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2769/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2770/3000], Step: [1/1], Loss: 0.4754\n",
      "Epoch: [2771/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2772/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2773/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2774/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2775/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2776/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2777/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2778/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2779/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2780/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2781/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2782/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2783/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2784/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2785/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2786/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2787/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2788/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2789/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2790/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2791/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2792/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2793/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2794/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2795/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2796/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2797/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2798/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2799/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2800/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2801/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2802/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2803/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2804/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2805/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2806/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2807/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2808/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2809/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2810/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2811/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2812/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2813/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2814/3000], Step: [1/1], Loss: 0.4753\n",
      "Epoch: [2815/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2816/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2817/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2818/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2819/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2820/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2821/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2822/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2823/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2824/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2825/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2826/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2827/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2828/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2829/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2830/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2831/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2832/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2833/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2834/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2835/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2836/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2837/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2838/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2839/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2840/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2841/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2842/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2843/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2844/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2845/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2846/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2847/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2848/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2849/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2850/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2851/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2852/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2853/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2854/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2855/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2856/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2857/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2858/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2859/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2860/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2861/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2862/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2863/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2864/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2865/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2866/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2867/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2868/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2869/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2870/3000], Step: [1/1], Loss: 0.4752\n",
      "Epoch: [2871/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2872/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2873/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2874/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2875/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2876/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2877/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2878/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2879/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2880/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2881/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2882/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2883/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2884/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2885/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2886/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2887/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2888/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2889/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2890/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2891/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2892/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2893/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2894/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2895/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2896/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2897/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2898/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2899/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2900/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2901/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2902/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2903/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2904/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2905/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2906/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2907/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2908/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2909/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2910/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2911/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2912/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2913/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2914/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2915/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2916/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2917/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2918/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2919/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2920/3000], Step: [1/1], Loss: 0.4751\n",
      "Epoch: [2921/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2922/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2923/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2924/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2925/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2926/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2927/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2928/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2929/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2930/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2931/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2932/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2933/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2934/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2935/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2936/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2937/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2938/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2939/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2940/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2941/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2942/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2943/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2944/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2945/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2946/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2947/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2948/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2949/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2950/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2951/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2952/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2953/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2954/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2955/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2956/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2957/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2958/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2959/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2960/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2961/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2962/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2963/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2964/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2965/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2966/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2967/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2968/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2969/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2970/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2971/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2972/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2973/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2974/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2975/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2976/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2977/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2978/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2979/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2980/3000], Step: [1/1], Loss: 0.4750\n",
      "Epoch: [2981/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2982/3000], Step: [1/1], Loss: 0.4750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2983/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2984/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2985/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2986/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2987/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2988/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2989/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2990/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2991/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2992/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2993/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2994/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2995/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2996/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2997/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2998/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [2999/3000], Step: [1/1], Loss: 0.4749\n",
      "Epoch: [3000/3000], Step: [1/1], Loss: 0.4749\n",
      "Accuracy of the model on the train images: 84 %\n",
      "Accuracy of the model on the test images: 87 %\n"
     ]
    }
   ],
   "source": [
    "model = train_and_test(data[train_ids], labels[train_ids], data[test_ids], labels[test_ids], verbose=True, batch_size=len(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
